{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM76kssdPK9qhBORkvS8xTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanpharamut/data_viz/blob/main/Project01%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpQybCvMEsri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfba1b2d-73f8-4f16-873d-68c83ea9bc1b"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/facebookresearch/consistent_depth.git\n",
        "%cd consistent_depth\n",
        "!git submodule update --init --recursive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'consistent_depth'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 57 (delta 0), reused 52 (delta 0), pack-reused 5\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n",
            "/content/consistent_depth\n",
            "Submodule 'monodepth/mannequin_challenge' (https://github.com/roxanneluo/mannequinchallenge.git) registered for path 'monodepth/mannequin_challenge'\n",
            "Submodule 'monodepth/midas_v2' (https://github.com/roxanneluo/MiDaS-1.git) registered for path 'monodepth/midas_v2'\n",
            "Submodule 'monodepth/monodepth2' (https://github.com/roxanneluo/monodepth2.git) registered for path 'monodepth/monodepth2'\n",
            "Submodule 'third_party/OpticalFlowToolkit' (https://github.com/roxanneluo/OpticalFlowToolkit.git) registered for path 'third_party/OpticalFlowToolkit'\n",
            "Submodule 'third_party/colmap' (https://github.com/colmap/colmap.git) registered for path 'third_party/colmap'\n",
            "Submodule 'flownet2' (https://github.com/roxanneluo/flownet2-pytorch.git) registered for path 'third_party/flownet2'\n",
            "Cloning into '/content/consistent_depth/monodepth/mannequin_challenge'...\n",
            "Cloning into '/content/consistent_depth/monodepth/midas_v2'...\n",
            "Cloning into '/content/consistent_depth/monodepth/monodepth2'...\n",
            "Cloning into '/content/consistent_depth/third_party/OpticalFlowToolkit'...\n",
            "Cloning into '/content/consistent_depth/third_party/colmap'...\n",
            "Cloning into '/content/consistent_depth/third_party/flownet2'...\n",
            "Submodule path 'monodepth/mannequin_challenge': checked out '826c33d4a9f50eb9bfd4b0eba731d893ccbbfa31'\n",
            "Submodule path 'monodepth/midas_v2': checked out '6cae4a6d3198efae398f07220aae4804c2f517ed'\n",
            "Submodule path 'monodepth/monodepth2': checked out '22d073ab881c1e3a8cfcdd147467d80b1d103327'\n",
            "Submodule path 'third_party/OpticalFlowToolkit': checked out '21e7eccd4f979f56ed4dc6e3ba03a5d90edb9bd7'\n",
            "Submodule path 'third_party/colmap': checked out '64d625a996a052cdf4f3f9151e9a5af7b8d6a5e1'\n",
            "Submodule 'doc/_build/html' (https://github.com/colmap/colmap.github.io.git) registered for path 'third_party/colmap/doc/_build/html'\n",
            "Cloning into '/content/consistent_depth/third_party/colmap/doc/_build/html'...\n",
            "Submodule path 'third_party/colmap/doc/_build/html': checked out '751fd602f81d3bb52b45bc3f4757113c18f3cd00'\n",
            "Submodule path 'third_party/flownet2': checked out 'e99b5cc2b8dde129cb0273ff43501da59fb9731e'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cleNUVwFS0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa95e54-c1ff-4527-b039-82a6bb0a6a6b"
      },
      "source": [
        "!./scripts/download_model.sh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allexport      \toff\n",
            "braceexpand    \ton\n",
            "emacs          \toff\n",
            "errexit        \ton\n",
            "errtrace       \toff\n",
            "functrace      \toff\n",
            "hashall        \ton\n",
            "histexpand     \toff\n",
            "history        \toff\n",
            "ignoreeof      \toff\n",
            "interactive-comments\ton\n",
            "keyword        \toff\n",
            "monitor        \toff\n",
            "noclobber      \toff\n",
            "noexec         \toff\n",
            "noglob         \toff\n",
            "nolog          \toff\n",
            "notify         \toff\n",
            "nounset        \toff\n",
            "onecmd         \toff\n",
            "physical       \toff\n",
            "pipefail       \toff\n",
            "posix          \toff\n",
            "privileged     \toff\n",
            "verbose        \toff\n",
            "vi             \toff\n",
            "xtrace         \ton\n",
            "++ mkdir -p checkpoints\n",
            "++ gdown 'https://drive.google.com/uc?id=1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da' -O checkpoints/flownet2.pth\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da\n",
            "To: /content/consistent_depth/checkpoints/flownet2.pth\n",
            "650MB [00:05, 113MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA4WsYaYlaah",
        "outputId": "c5c00907-c152-4fb1-8512-715b5842e637"
      },
      "source": [
        "!./scripts/install.sh"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.17.2)\n",
            "Requirement already satisfied: opencv-contrib-python==3.4.2.16 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (3.4.2.16)\n",
            "Requirement already satisfied: torch==1.4.0+cu100 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (1.4.0+cu100)\n",
            "Requirement already satisfied: torchvision==0.5.0+cu100 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (0.5.0+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (1.19.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2.5.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (1.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (0.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (4.59.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (1.2.2)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (3.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (3.13.0)\n",
            "Requirement already satisfied: pypng in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (0.0.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from torchvision==0.5.0+cu100->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/site-packages (from torchvision==0.5.0+cu100->-r requirements.txt (line 7)) (8.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.6/site-packages (from h5py->-r requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 2)) (1.5.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 2)) (3.3.4)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 2)) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 2)) (2020.9.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 2)) (2.5.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 2)) (0.10.0)\n",
            "Collecting decorator<5,>=4.3\n",
            "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (1.38.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (1.31.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (2.25.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (52.0.0.post20210125)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (2.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (0.13.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorboard->-r requirements.txt (line 9)) (0.36.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 9)) (4.5.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 9)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 9)) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 9)) (3.1.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard->-r requirements.txt (line 9)) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/site-packages (from gdown->-r requirements.txt (line 17)) (3.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 9)) (1.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->-r requirements.txt (line 9)) (3.10.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->-r requirements.txt (line 9)) (3.4.1)\n",
            "Installing collected packages: decorator\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 5.0.9\n",
            "    Uninstalling decorator-5.0.9:\n",
            "      Successfully uninstalled decorator-5.0.9\n",
            "Successfully installed decorator-4.4.2\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "/content/consistent_depth/third_party/flownet2 /content/consistent_depth\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating correlation_cuda.egg-info\n",
            "writing correlation_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to correlation_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to correlation_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "reading manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'correlation_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c correlation_cuda.cc -o build/temp.linux-x86_64-3.6/correlation_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=correlation_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c correlation_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/correlation_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=correlation_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:386:99:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channels_first_fwd_1\", ([&] {\n",
            "                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:386:317:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channels_first_fwd_1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:386:345:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channels_first_fwd_1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:386:605:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channels_first_fwd_1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:386:632:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channels_first_fwd_1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:386:903:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channels_first_fwd_1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:386:934:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channels_first_fwd_1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:393:99:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"channels_first_fwd_2\", ([&] {\n",
            "                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:393:317:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"channels_first_fwd_2\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:393:345:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"channels_first_fwd_2\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:393:605:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"channels_first_fwd_2\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:393:632:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"channels_first_fwd_2\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:393:903:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"channels_first_fwd_2\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:393:934:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"channels_first_fwd_2\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:99:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:328:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:400:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:469:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:748:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:819:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:887:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:1177:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:1252:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:403:1324:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"correlation_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:495:99:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:495:317:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:495:345:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:495:605:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:495:632:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:495:903:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:495:934:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:507:99:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:507:317:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:507:345:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:507:605:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:507:632:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:507:903:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:507:934:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:99:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:343:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:415:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:487:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:781:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:852:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:923:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:1228:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:1303:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:524:1378:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input2.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:100:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:344:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:416:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:488:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:782:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:853:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:924:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:1229:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:1304:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcorrelation_cuda_kernel.cu:541:1379:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(rInput1.type(), \"lltm_forward_cuda\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "g++ -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/correlation_cuda.o build/temp.linux-x86_64-3.6/correlation_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/correlation_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/correlation_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for correlation_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/correlation_cuda.py to correlation_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.correlation_cuda.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing correlation_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "removing '/root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg' (and everything under it)\n",
            "creating /root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting correlation_cuda-0.0.0-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "correlation-cuda 0.0.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for correlation-cuda==0.0.0\n",
            "Finished processing dependencies for correlation-cuda==0.0.0\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating resample2d_cuda.egg-info\n",
            "writing resample2d_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to resample2d_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to resample2d_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "reading manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'resample2d_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c resample2d_cuda.cc -o build/temp.linux-x86_64-3.6/resample2d_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c resample2d_kernel.cu -o build/temp.linux-x86_64-3.6/resample2d_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid resample2d_kernel_forward(at::Tensor&, at::Tensor&, at::Tensor&, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:221:173:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_update_output<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:221:225:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_update_output<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:221:277:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_update_output<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid resample2d_kernel_backward(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:269:175:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_backward_input1<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:269:227:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_backward_input1<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:269:283:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_backward_input1<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:269:347:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_backward_input1<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:298:175:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_backward_input2<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:298:227:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_backward_input2<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:298:283:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_backward_input2<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kresample2d_kernel.cu:298:347:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "         kernel_resample2d_backward_input2<float><<< (n + CUDA_NUM_THREADS - 1)/CUDA_NUM_THREADS, CUDA_NUM_THREADS, 0, at::cuda::getCurrentCUDAStream() >>>(\n",
            "                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "g++ -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/resample2d_cuda.o build/temp.linux-x86_64-3.6/resample2d_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/resample2d_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/resample2d_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for resample2d_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resample2d_cuda.py to resample2d_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.resample2d_cuda.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "removing '/root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg' (and everything under it)\n",
            "creating /root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "resample2d-cuda 0.0.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for resample2d-cuda==0.0.0\n",
            "Finished processing dependencies for resample2d-cuda==0.0.0\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating channelnorm_cuda.egg-info\n",
            "writing channelnorm_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to channelnorm_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to channelnorm_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "reading manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'channelnorm_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c channelnorm_cuda.cc -o build/temp.linux-x86_64-3.6/channelnorm_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=channelnorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c channelnorm_kernel.cu -o build/temp.linux-x86_64-3.6/channelnorm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=channelnorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.6/site-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:111:99:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_forward\", ([&] {\n",
            "                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:111:366:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:111:421:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:111:717:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:111:771:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:111:1078:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:111:1136:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_forward\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:99:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:368:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:423:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:482:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:549:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:855:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:909:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:967:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:1033:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:1350:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:1408:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:1470:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kchannelnorm_kernel.cu:152:1540:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input1.type(), \"channelnorm_backward_input1\", ([&] {\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "g++ -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/channelnorm_cuda.o build/temp.linux-x86_64-3.6/channelnorm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/channelnorm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/channelnorm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for channelnorm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/channelnorm_cuda.py to channelnorm_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.channelnorm_cuda.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "removing '/root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg' (and everything under it)\n",
            "creating /root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "channelnorm-cuda 0.0.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for channelnorm-cuda==0.0.0\n",
            "Finished processing dependencies for channelnorm-cuda==0.0.0\n",
            "/content/consistent_depth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJgA5KLClipM",
        "outputId": "0079172d-3929-4649-e9a4-e45ab4a2780e"
      },
      "source": [
        "!./scripts/download_demo.sh results/ayush"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allexport      \toff\n",
            "braceexpand    \ton\n",
            "emacs          \toff\n",
            "errexit        \ton\n",
            "errtrace       \toff\n",
            "functrace      \toff\n",
            "hashall        \ton\n",
            "histexpand     \toff\n",
            "history        \toff\n",
            "ignoreeof      \toff\n",
            "interactive-comments\ton\n",
            "keyword        \toff\n",
            "monitor        \toff\n",
            "noclobber      \toff\n",
            "noexec         \toff\n",
            "noglob         \toff\n",
            "nolog          \toff\n",
            "notify         \toff\n",
            "nounset        \toff\n",
            "onecmd         \toff\n",
            "physical       \toff\n",
            "pipefail       \toff\n",
            "posix          \toff\n",
            "privileged     \toff\n",
            "verbose        \toff\n",
            "vi             \toff\n",
            "xtrace         \ton\n",
            "++ mkdir -p checkpoints\n",
            "++ gdown 'https://drive.google.com/uc?id=1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da' -O checkpoints/flownet2.pth\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da\n",
            "To: /content/consistent_depth/checkpoints/flownet2.pth\n",
            "650MB [00:03, 191MB/s]\n",
            "allexport      \toff\n",
            "braceexpand    \ton\n",
            "emacs          \toff\n",
            "errexit        \ton\n",
            "errtrace       \toff\n",
            "functrace      \toff\n",
            "hashall        \ton\n",
            "histexpand     \toff\n",
            "history        \toff\n",
            "ignoreeof      \toff\n",
            "interactive-comments\ton\n",
            "keyword        \toff\n",
            "monitor        \toff\n",
            "noclobber      \toff\n",
            "noexec         \toff\n",
            "noglob         \toff\n",
            "nolog          \toff\n",
            "notify         \toff\n",
            "nounset        \toff\n",
            "onecmd         \toff\n",
            "physical       \toff\n",
            "pipefail       \toff\n",
            "posix          \toff\n",
            "privileged     \toff\n",
            "verbose        \toff\n",
            "vi             \toff\n",
            "xtrace         \ton\n",
            "++ results_dir=results/ayush\n",
            "++ mkdir -p data/videos/\n",
            "++ wget 'https://www.dropbox.com/s/9a2kb7flg3o1eb5/ayush_color.mp4?dl=1' -O data/videos/ayush.mp4\n",
            "--2021-06-16 16:12:50--  https://www.dropbox.com/s/9a2kb7flg3o1eb5/ayush_color.mp4?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/9a2kb7flg3o1eb5/ayush_color.mp4 [following]\n",
            "--2021-06-16 16:12:50--  https://www.dropbox.com/s/dl/9a2kb7flg3o1eb5/ayush_color.mp4\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucfa8a467820d5f97e43908e26c0.dl.dropboxusercontent.com/cd/0/get/BQjsWx3eH-3NI1NTUVabDqkpfEAIqvsCS09YvpUTJ2bhxHYn4CkrpNOrUISUcOdYyX_xmy26d1vyRSxsPN_Rgt2qqZQPk1DFvMgjI5uE-yADaKHbpLWnWG5ClK2tU__ST3qfMZkpgrs7toXCOwcOALZt/file?dl=1# [following]\n",
            "--2021-06-16 16:12:51--  https://ucfa8a467820d5f97e43908e26c0.dl.dropboxusercontent.com/cd/0/get/BQjsWx3eH-3NI1NTUVabDqkpfEAIqvsCS09YvpUTJ2bhxHYn4CkrpNOrUISUcOdYyX_xmy26d1vyRSxsPN_Rgt2qqZQPk1DFvMgjI5uE-yADaKHbpLWnWG5ClK2tU__ST3qfMZkpgrs7toXCOwcOALZt/file?dl=1\n",
            "Resolving ucfa8a467820d5f97e43908e26c0.dl.dropboxusercontent.com (ucfa8a467820d5f97e43908e26c0.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucfa8a467820d5f97e43908e26c0.dl.dropboxusercontent.com (ucfa8a467820d5f97e43908e26c0.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52605435 (50M) [application/binary]\n",
            "Saving to: ‘data/videos/ayush.mp4’\n",
            "\n",
            "data/videos/ayush.m 100%[===================>]  50.17M  83.7MB/s    in 0.6s    \n",
            "\n",
            "2021-06-16 16:12:52 (83.7 MB/s) - ‘data/videos/ayush.mp4’ saved [52605435/52605435]\n",
            "\n",
            "++ mkdir -p results/ayush\n",
            "++ wget 'https://www.dropbox.com/s/7mbvu60qbs7hzod/ayush_colmap.zip?dl=1' -O results/ayush/ayush_colmap.zip\n",
            "--2021-06-16 16:12:52--  https://www.dropbox.com/s/7mbvu60qbs7hzod/ayush_colmap.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/7mbvu60qbs7hzod/ayush_colmap.zip [following]\n",
            "--2021-06-16 16:12:52--  https://www.dropbox.com/s/dl/7mbvu60qbs7hzod/ayush_colmap.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucad120dcef7c97bdc2c1de3ecbf.dl.dropboxusercontent.com/cd/0/get/BQisegZ6vQ8Vg78byeKI1tY5Q4MP_GNRHn8PP_8sqDqyUSHQqbNVyZzaKVMXiqx_U1_VKkmsWRusUAz02j7KFB9g971rhfabt1SJ3Wgmn5Pf426zOx2Z2oxaLXS8qZzC7k8iFMDq2vyxLuLyAjbH-Zpf/file?dl=1# [following]\n",
            "--2021-06-16 16:12:52--  https://ucad120dcef7c97bdc2c1de3ecbf.dl.dropboxusercontent.com/cd/0/get/BQisegZ6vQ8Vg78byeKI1tY5Q4MP_GNRHn8PP_8sqDqyUSHQqbNVyZzaKVMXiqx_U1_VKkmsWRusUAz02j7KFB9g971rhfabt1SJ3Wgmn5Pf426zOx2Z2oxaLXS8qZzC7k8iFMDq2vyxLuLyAjbH-Zpf/file?dl=1\n",
            "Resolving ucad120dcef7c97bdc2c1de3ecbf.dl.dropboxusercontent.com (ucad120dcef7c97bdc2c1de3ecbf.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucad120dcef7c97bdc2c1de3ecbf.dl.dropboxusercontent.com (ucad120dcef7c97bdc2c1de3ecbf.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31811430 (30M) [application/binary]\n",
            "Saving to: ‘results/ayush/ayush_colmap.zip’\n",
            "\n",
            "results/ayush/ayush 100%[===================>]  30.34M   163MB/s    in 0.2s    \n",
            "\n",
            "2021-06-16 16:12:53 (163 MB/s) - ‘results/ayush/ayush_colmap.zip’ saved [31811430/31811430]\n",
            "\n",
            "++ unzip results/ayush/ayush_colmap.zip -d results/ayush\n",
            "Archive:  results/ayush/ayush_colmap.zip\n",
            "   creating: results/ayush/colmap_dense/\n",
            "  inflating: results/ayush/colmap_dense/metadata.npz  \n",
            "   creating: results/ayush/__MACOSX/\n",
            "   creating: results/ayush/__MACOSX/colmap_dense/\n",
            "  inflating: results/ayush/__MACOSX/colmap_dense/._metadata.npz  \n",
            "  inflating: results/ayush/__MACOSX/._colmap_dense  \n",
            "   creating: results/ayush/depth_colmap_dense/\n",
            "   creating: results/ayush/depth_colmap_dense/depth/\n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000022.raw  \n",
            "   creating: results/ayush/__MACOSX/depth_colmap_dense/\n",
            "   creating: results/ayush/__MACOSX/depth_colmap_dense/depth/\n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000022.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000036.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000036.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000088.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000088.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000063.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000063.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000077.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000077.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000076.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000076.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000062.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000062.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000089.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000089.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000037.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000037.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000023.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000023.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000009.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000009.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000035.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000035.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000021.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000021.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000048.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000048.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000074.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000074.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000060.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000060.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000061.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000061.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000075.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000075.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000049.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000049.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000020.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000020.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000034.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000034.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000008.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000008.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000030.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000030.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000024.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000024.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000018.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000018.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000071.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000071.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000065.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000065.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000059.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000059.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000058.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000058.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000064.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000064.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000070.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000070.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000019.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000019.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000025.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000025.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000031.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000031.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000027.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000027.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000033.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000033.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000066.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000066.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000072.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000072.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000073.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000073.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000067.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000067.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000032.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000032.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000026.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000026.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000082.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000082.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000069.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000069.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000041.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000041.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000055.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000055.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000028.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000028.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000000.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000000.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000014.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000014.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000015.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000015.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000001.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000001.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000029.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000029.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000054.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000054.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000040.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000040.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000068.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000068.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000083.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000083.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000081.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000081.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000056.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000056.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000042.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000042.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000017.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000017.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000003.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000003.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000002.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000002.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000016.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000016.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000043.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000043.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000057.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000057.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000080.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000080.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000090.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000090.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000084.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000084.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000053.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000053.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000047.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000047.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000012.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000012.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000006.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000006.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000007.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000007.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000013.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000013.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000046.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000046.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000052.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000052.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000085.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000085.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000091.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000091.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000087.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000087.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000044.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000044.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000050.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000050.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000078.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000078.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000005.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000005.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000011.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000011.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000039.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000039.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000038.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000038.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000010.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000010.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000004.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000004.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000079.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000079.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000051.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000051.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000045.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000045.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000086.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000086.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000048.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000048.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000060.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000060.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000074.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000074.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000009.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000009.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000021.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000021.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000035.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000035.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000034.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000034.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000020.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000020.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000008.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000008.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000075.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000075.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000061.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000061.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000049.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000049.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000088.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000088.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000077.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000077.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000063.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000063.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000036.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000036.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000022.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000022.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000023.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000023.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000037.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000037.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000062.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000062.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000076.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000076.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000089.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000089.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000072.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000072.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000066.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000066.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000033.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000033.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000027.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000027.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000026.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000026.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000032.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000032.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000067.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000067.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000073.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000073.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000065.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000065.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000071.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000071.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000059.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000059.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000024.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000024.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000030.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000030.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000018.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000018.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000019.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000019.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000031.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000031.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000025.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000025.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000058.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000058.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000070.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000070.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000064.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000064.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000003.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000003.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000017.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000017.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000081.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000081.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000042.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000042.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000056.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000056.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000057.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000057.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000043.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000043.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000080.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000080.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000016.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000016.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000002.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000002.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000028.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000028.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000014.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000014.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000000.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000000.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000082.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000082.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000069.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000069.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000055.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000055.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000041.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000041.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000040.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000040.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000054.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000054.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000068.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000068.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000083.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000083.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000001.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000001.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000015.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000015.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000029.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000029.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000011.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000011.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000005.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000005.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000039.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000039.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000087.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000087.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000050.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000050.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000044.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000044.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000078.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000078.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000079.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000079.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000045.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000045.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000051.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000051.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000086.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000086.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000038.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000038.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000004.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000004.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000010.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000010.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000006.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000006.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000012.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000012.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000084.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000084.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000090.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000090.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000047.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000047.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000053.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000053.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000052.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000052.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000046.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000046.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000091.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000091.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000085.png  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000085.png  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000013.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000013.raw  \n",
            "  inflating: results/ayush/depth_colmap_dense/depth/frame_000007.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/depth/._frame_000007.raw  \n",
            "  inflating: results/ayush/__MACOSX/depth_colmap_dense/._depth  \n",
            "  inflating: results/ayush/__MACOSX/._depth_colmap_dense  \n",
            "++ rm results/ayush/ayush_colmap.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0clmFX2KmJ7T",
        "outputId": "6fda4d28-61b4-4324-f9a7-7eaa23f10a86"
      },
      "source": [
        "!python main.py --video_file data/videos/ayush.mp4 --path results/ayush \\\n",
        "  --camera_params \"1671.770118, 540, 960\" --camera_model \"SIMPLE_PINHOLE\" \\\n",
        "  --make_video\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Parameters -------------\n",
            "align: 16\n",
            "batch_size: 4\n",
            "camera_model: SIMPLE_PINHOLE\n",
            "camera_params: 1671.770118, 540, 960\n",
            "colmap_bin_path: colmap\n",
            "configure: default\n",
            "dense_frame_ratio: 0.95\n",
            "dense_pixel_ratio: 0.3\n",
            "display_freq: 100\n",
            "ffmpeg: ffmpeg\n",
            "flow_checkpoint: FlowNet2\n",
            "flow_ops: ['hierarchical2']\n",
            "frame_range: ''\n",
            "initialize_pose: False\n",
            "lambda_parameter: 0\n",
            "lambda_reprojection: 1.0\n",
            "lambda_view_baseline: 0.1\n",
            "learning_rate: 0.0004\n",
            "log_dir: None\n",
            "make_video: True\n",
            "matcher: exhaustive\n",
            "model_type: mc\n",
            "num_epochs: 20\n",
            "op: all\n",
            "optimizer: Adam\n",
            "overlap_ratio: 0.2\n",
            "path: results/ayush\n",
            "print_freq: 1\n",
            "refine_intrinsics: False\n",
            "save_epoch_freq: 1\n",
            "size: 384\n",
            "sparse: False\n",
            "val_epoch_freq: 1\n",
            "video_file: data/videos/ayush.mp4\n",
            "-------------------------------------\n",
            "\n",
            "----------------------------------\n",
            "Processing dataset 'results/ayush'\n",
            "----------------------------------\n",
            "Output directory: results/ayush/R_hierarchical2_mc\n",
            "\n",
            "**************************\n",
            "****  Extracting PTS  ****\n",
            "**************************\n",
            "92 frames detected (1080 x 1920).\n",
            "frames.txt exists, checked OK.\n",
            "\n",
            "*****************************\n",
            "****  Extracting frames  ****\n",
            "*****************************\n",
            "Frames found, checked OK.\n",
            "\n",
            "************************************\n",
            "****  Downscaling frames (raw)  ****\n",
            "************************************\n",
            "Frames found, checked OK.\n",
            "\n",
            "************************************\n",
            "****  Downscaling frames (png)  ****\n",
            "************************************\n",
            "Frames found, checked OK.\n",
            "\n",
            "*****************************************\n",
            "****  Downscaling frames (for flow)  ****\n",
            "*****************************************\n",
            "Frames found, checked OK.\n",
            "\n",
            "*********************************\n",
            "****  Compute initial depth  ****\n",
            "*********************************\n",
            "Fine-tuning directory: 'results/ayush/R_hierarchical2_mc/B0.1_R1.0_PL1-0_LR0.0004_BS4_Oadam'\n",
            "Found cache checkpoints/mc.pth\n",
            "THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=50 error=38 : no CUDA-capable device is detected\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 13, in <module>\n",
            "    dp.process(params)\n",
            "  File \"/content/consistent_depth/process.py\", line 117, in process\n",
            "    return self.pipeline(params)\n",
            "  File \"/content/consistent_depth/process.py\", line 57, in pipeline\n",
            "    ft = DepthFineTuner(self.out_dir, frames, params)\n",
            "  File \"/content/consistent_depth/depth_fine_tuning.py\", line 153, in __init__\n",
            "    self.model = model()\n",
            "  File \"/content/consistent_depth/monodepth/mannequin_challenge_model.py\", line 41, in __init__\n",
            "    self.model = FixedMcModel(params)\n",
            "  File \"/content/consistent_depth/monodepth/mannequin_challenge/models/pix2pix_model.py\", line 109, in __init__\n",
            "    new_model.to(\"cuda\")\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 425, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 201, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 201, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 201, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 223, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 423, in convert\n",
            "    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 197, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsXXYUSEmSL8",
        "outputId": "f28a8a10-6777-4346-ecad-dc24be9ec57f"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Using cached wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=b545bbd58ef9c729d19b5640609180178c894bffed0402fc69f97d48abf15261\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/1d/93/c863ee832230df5cfc25ca497b3e88e0ee3ea9e44adc46ac62\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Uo1IOQm5FM",
        "outputId": "1f3ea2e9-3224-4198-f3ea-44d830b890a1"
      },
      "source": [
        "!pip install pypng"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pypng\n",
            "  Using cached pypng-0.0.20.tar.gz (649 kB)\n",
            "Building wheels for collected packages: pypng\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-py3-none-any.whl size=67162 sha256=b3bb79d7f6791fb51bc5bce592572e7b386a43770bf9126d8af888badf7a2650\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/d3/cf/b82186f85e4c9d159bc4233fbd37607e766c241b78b09f1e8f\n",
            "Successfully built pypng\n",
            "Installing collected packages: pypng\n",
            "Successfully installed pypng-0.0.20\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r_j9XdPsA9P",
        "outputId": "7b0214af-a4ff-4433-c753-4a5383eced52"
      },
      "source": [
        "!which python # should return /usr/local/bin/python"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TC4jfkRsXQF",
        "outputId": "7cac37e2-0809-4c33-d70c-8fc94852b5b5"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdHoIayEsZxP",
        "outputId": "25cf197e-d78c-4c70-82b7-274c669ff334"
      },
      "source": [
        "!echo $PYTHONPATH"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6Slaukksg-Z",
        "outputId": "4dddabcc-0a79-47b2-8f20-fd9c9e06c08f"
      },
      "source": [
        "%env PYTHONPATH="
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9LzsXwWskHj",
        "outputId": "d7427492-75ad-4de3-c6df-e98ca6394068"
      },
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2021-06-16 16:40:54--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2021-06-16 16:40:54--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 7.06M 8s\n",
            "    50K .......... .......... .......... .......... ..........  0% 6.83M 8s\n",
            "   100K .......... .......... .......... .......... ..........  0% 21.3M 6s\n",
            "   150K .......... .......... .......... .......... ..........  0% 21.4M 5s\n",
            "   200K .......... .......... .......... .......... ..........  0% 11.7M 5s\n",
            "   250K .......... .......... .......... .......... ..........  0% 36.8M 5s\n",
            "   300K .......... .......... .......... .......... ..........  0% 20.4M 4s\n",
            "   350K .......... .......... .......... .......... ..........  0% 38.8M 4s\n",
            "   400K .......... .......... .......... .......... ..........  0% 28.8M 4s\n",
            "   450K .......... .......... .......... .......... ..........  0% 40.5M 3s\n",
            "   500K .......... .......... .......... .......... ..........  0% 69.6M 3s\n",
            "   550K .......... .......... .......... .......... ..........  1% 45.8M 3s\n",
            "   600K .......... .......... .......... .......... ..........  1% 50.6M 3s\n",
            "   650K .......... .......... .......... .......... ..........  1% 49.0M 3s\n",
            "   700K .......... .......... .......... .......... ..........  1% 49.1M 3s\n",
            "   750K .......... .......... .......... .......... ..........  1% 48.2M 3s\n",
            "   800K .......... .......... .......... .......... ..........  1% 44.7M 2s\n",
            "   850K .......... .......... .......... .......... ..........  1% 49.5M 2s\n",
            "   900K .......... .......... .......... .......... ..........  1% 58.2M 2s\n",
            "   950K .......... .......... .......... .......... ..........  1% 43.5M 2s\n",
            "  1000K .......... .......... .......... .......... ..........  1% 64.3M 2s\n",
            "  1050K .......... .......... .......... .......... ..........  1% 53.5M 2s\n",
            "  1100K .......... .......... .......... .......... ..........  2%  125M 2s\n",
            "  1150K .......... .......... .......... .......... ..........  2%  127M 2s\n",
            "  1200K .......... .......... .......... .......... ..........  2%  285M 2s\n",
            "  1250K .......... .......... .......... .......... ..........  2%  156M 2s\n",
            "  1300K .......... .......... .......... .......... ..........  2%  151M 2s\n",
            "  1350K .......... .......... .......... .......... ..........  2%  180M 2s\n",
            "  1400K .......... .......... .......... .......... ..........  2%  186M 2s\n",
            "  1450K .......... .......... .......... .......... ..........  2%  163M 2s\n",
            "  1500K .......... .......... .......... .......... ..........  2%  139M 2s\n",
            "  1550K .......... .......... .......... .......... ..........  2%  128M 2s\n",
            "  1600K .......... .......... .......... .......... ..........  2%  124M 2s\n",
            "  1650K .......... .......... .......... .......... ..........  2%  166M 1s\n",
            "  1700K .......... .......... .......... .......... ..........  3%  131M 1s\n",
            "  1750K .......... .......... .......... .......... ..........  3% 59.9M 1s\n",
            "  1800K .......... .......... .......... .......... ..........  3% 28.0M 1s\n",
            "  1850K .......... .......... .......... .......... ..........  3% 33.5M 1s\n",
            "  1900K .......... .......... .......... .......... ..........  3% 33.6M 1s\n",
            "  1950K .......... .......... .......... .......... ..........  3% 64.1M 1s\n",
            "  2000K .......... .......... .......... .......... ..........  3% 82.6M 1s\n",
            "  2050K .......... .......... .......... .......... ..........  3% 84.0M 1s\n",
            "  2100K .......... .......... .......... .......... ..........  3% 72.4M 1s\n",
            "  2150K .......... .......... .......... .......... ..........  3% 31.5M 1s\n",
            "  2200K .......... .......... .......... .......... ..........  3% 40.3M 1s\n",
            "  2250K .......... .......... .......... .......... ..........  4% 72.2M 1s\n",
            "  2300K .......... .......... .......... .......... ..........  4% 75.0M 1s\n",
            "  2350K .......... .......... .......... .......... ..........  4% 63.5M 1s\n",
            "  2400K .......... .......... .......... .......... ..........  4% 90.7M 1s\n",
            "  2450K .......... .......... .......... .......... ..........  4% 64.0M 1s\n",
            "  2500K .......... .......... .......... .......... ..........  4% 64.9M 1s\n",
            "  2550K .......... .......... .......... .......... ..........  4% 13.9M 1s\n",
            "  2600K .......... .......... .......... .......... ..........  4% 69.1M 1s\n",
            "  2650K .......... .......... .......... .......... ..........  4% 80.8M 1s\n",
            "  2700K .......... .......... .......... .......... ..........  4% 73.2M 1s\n",
            "  2750K .......... .......... .......... .......... ..........  4% 24.9M 1s\n",
            "  2800K .......... .......... .......... .......... ..........  4% 52.0M 1s\n",
            "  2850K .......... .......... .......... .......... ..........  5% 66.8M 1s\n",
            "  2900K .......... .......... .......... .......... ..........  5%  166M 1s\n",
            "  2950K .......... .......... .......... .......... ..........  5%  248M 1s\n",
            "  3000K .......... .......... .......... .......... ..........  5%  289M 1s\n",
            "  3050K .......... .......... .......... .......... ..........  5%  282M 1s\n",
            "  3100K .......... .......... .......... .......... ..........  5%  274M 1s\n",
            "  3150K .......... .......... .......... .......... ..........  5%  207M 1s\n",
            "  3200K .......... .......... .......... .......... ..........  5%  277M 1s\n",
            "  3250K .......... .......... .......... .......... ..........  5%  288M 1s\n",
            "  3300K .......... .......... .......... .......... ..........  5% 63.8M 1s\n",
            "  3350K .......... .......... .......... .......... ..........  5%  232M 1s\n",
            "  3400K .......... .......... .......... .......... ..........  6%  300M 1s\n",
            "  3450K .......... .......... .......... .......... ..........  6%  275M 1s\n",
            "  3500K .......... .......... .......... .......... ..........  6%  290M 1s\n",
            "  3550K .......... .......... .......... .......... ..........  6%  211M 1s\n",
            "  3600K .......... .......... .......... .......... ..........  6%  270M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6%  290M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6%  293M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6% 65.8M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6% 71.1M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6% 49.6M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6% 83.6M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7% 70.5M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7% 73.8M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7% 91.4M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7% 30.8M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7% 56.5M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7% 29.6M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7% 70.6M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7% 73.8M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7% 63.0M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7% 85.1M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7% 50.2M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7% 44.6M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8% 52.4M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8% 53.4M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8% 73.0M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8% 82.6M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8% 59.8M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8% 74.3M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8% 87.3M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8% 38.9M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8% 53.2M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8% 57.8M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8% 71.9M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9% 54.7M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9% 63.9M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9% 75.3M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9%  143M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9%  252M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9%  243M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9%  287M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9%  298M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9%  286M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9%  244M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9%  245M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9% 89.3M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10%  241M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10%  232M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10%  287M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10%  292M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10%  298M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10%  226M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10%  306M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10%  234M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10%  274M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10%  270M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10%  282M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11%  292M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11%  101M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11% 32.9M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11% 73.5M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11% 85.3M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11% 72.2M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11% 62.1M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11% 34.3M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11% 79.0M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11% 44.5M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11% 27.6M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11% 79.7M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12% 73.0M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12% 65.8M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12% 36.6M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12% 57.8M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12% 61.5M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12% 57.8M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12% 51.4M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12% 73.2M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12% 80.7M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12% 69.3M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12% 38.9M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13% 51.6M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13% 67.9M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13% 65.7M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13% 49.9M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13% 65.2M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13% 98.2M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13%  180M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13%  153M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13%  170M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13%  175M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13%  182M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14%  146M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14% 84.6M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14%  219M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14% 99.7M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14%  221M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14%  298M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14%  181M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14%  197M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14% 87.7M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14%  201M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14% 98.9M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14%  189M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 15%  167M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 15% 40.1M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 15% 32.5M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 15% 66.1M 1s\n",
            "  8750K .......... .......... .......... .......... .......... 15% 27.9M 1s\n",
            "  8800K .......... .......... .......... .......... .......... 15%  145M 1s\n",
            "  8850K .......... .......... .......... .......... .......... 15%  152M 1s\n",
            "  8900K .......... .......... .......... .......... .......... 15%  263M 1s\n",
            "  8950K .......... .......... .......... .......... .......... 15% 49.7M 1s\n",
            "  9000K .......... .......... .......... .......... .......... 15%  217M 1s\n",
            "  9050K .......... .......... .......... .......... .......... 15%  198M 1s\n",
            "  9100K .......... .......... .......... .......... .......... 16%  297M 1s\n",
            "  9150K .......... .......... .......... .......... .......... 16%  224M 1s\n",
            "  9200K .......... .......... .......... .......... .......... 16%  213M 1s\n",
            "  9250K .......... .......... .......... .......... .......... 16%  210M 1s\n",
            "  9300K .......... .......... .......... .......... .......... 16%  289M 1s\n",
            "  9350K .......... .......... .......... .......... .......... 16% 92.7M 1s\n",
            "  9400K .......... .......... .......... .......... .......... 16%  202M 1s\n",
            "  9450K .......... .......... .......... .......... .......... 16%  268M 1s\n",
            "  9500K .......... .......... .......... .......... .......... 16%  293M 1s\n",
            "  9550K .......... .......... .......... .......... .......... 16%  230M 1s\n",
            "  9600K .......... .......... .......... .......... .......... 16%  296M 1s\n",
            "  9650K .......... .......... .......... .......... .......... 16%  229M 1s\n",
            "  9700K .......... .......... .......... .......... .......... 17%  221M 1s\n",
            "  9750K .......... .......... .......... .......... .......... 17%  276M 1s\n",
            "  9800K .......... .......... .......... .......... .......... 17%  181M 1s\n",
            "  9850K .......... .......... .......... .......... .......... 17%  174M 1s\n",
            "  9900K .......... .......... .......... .......... .......... 17%  114M 1s\n",
            "  9950K .......... .......... .......... .......... .......... 17%  206M 1s\n",
            " 10000K .......... .......... .......... .......... .......... 17%  294M 1s\n",
            " 10050K .......... .......... .......... .......... .......... 17% 53.5M 1s\n",
            " 10100K .......... .......... .......... .......... .......... 17% 50.8M 1s\n",
            " 10150K .......... .......... .......... .......... .......... 17% 96.4M 1s\n",
            " 10200K .......... .......... .......... .......... .......... 17%  117M 1s\n",
            " 10250K .......... .......... .......... .......... .......... 18%  290M 1s\n",
            " 10300K .......... .......... .......... .......... .......... 18%  256M 1s\n",
            " 10350K .......... .......... .......... .......... .......... 18%  227M 1s\n",
            " 10400K .......... .......... .......... .......... .......... 18%  245M 1s\n",
            " 10450K .......... .......... .......... .......... .......... 18%  218M 1s\n",
            " 10500K .......... .......... .......... .......... .......... 18% 84.2M 1s\n",
            " 10550K .......... .......... .......... .......... .......... 18%  205M 1s\n",
            " 10600K .......... .......... .......... .......... .......... 18%  235M 1s\n",
            " 10650K .......... .......... .......... .......... .......... 18%  244M 1s\n",
            " 10700K .......... .......... .......... .......... .......... 18%  189M 1s\n",
            " 10750K .......... .......... .......... .......... .......... 18%  148M 1s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  120M 1s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  160M 1s\n",
            " 10900K .......... .......... .......... .......... .......... 19%  160M 1s\n",
            " 10950K .......... .......... .......... .......... .......... 19%  162M 1s\n",
            " 11000K .......... .......... .......... .......... .......... 19%  201M 1s\n",
            " 11050K .......... .......... .......... .......... .......... 19%  269M 1s\n",
            " 11100K .......... .......... .......... .......... .......... 19%  280M 1s\n",
            " 11150K .......... .......... .......... .......... .......... 19%  208M 1s\n",
            " 11200K .......... .......... .......... .......... .......... 19%  275M 1s\n",
            " 11250K .......... .......... .......... .......... .......... 19%  162M 1s\n",
            " 11300K .......... .......... .......... .......... .......... 19% 68.2M 1s\n",
            " 11350K .......... .......... .......... .......... .......... 19%  196M 1s\n",
            " 11400K .......... .......... .......... .......... .......... 20%  236M 1s\n",
            " 11450K .......... .......... .......... .......... .......... 20%  284M 1s\n",
            " 11500K .......... .......... .......... .......... .......... 20%  274M 1s\n",
            " 11550K .......... .......... .......... .......... .......... 20%  236M 1s\n",
            " 11600K .......... .......... .......... .......... .......... 20%  257M 1s\n",
            " 11650K .......... .......... .......... .......... .......... 20% 71.6M 1s\n",
            " 11700K .......... .......... .......... .......... .......... 20% 24.9M 1s\n",
            " 11750K .......... .......... .......... .......... .......... 20%  234M 1s\n",
            " 11800K .......... .......... .......... .......... .......... 20%  223M 1s\n",
            " 11850K .......... .......... .......... .......... .......... 20%  286M 1s\n",
            " 11900K .......... .......... .......... .......... .......... 20%  248M 1s\n",
            " 11950K .......... .......... .......... .......... .......... 21%  225M 1s\n",
            " 12000K .......... .......... .......... .......... .......... 21%  288M 1s\n",
            " 12050K .......... .......... .......... .......... .......... 21%  244M 1s\n",
            " 12100K .......... .......... .......... .......... .......... 21%  285M 1s\n",
            " 12150K .......... .......... .......... .......... .......... 21%  256M 1s\n",
            " 12200K .......... .......... .......... .......... .......... 21%  240M 1s\n",
            " 12250K .......... .......... .......... .......... .......... 21%  290M 1s\n",
            " 12300K .......... .......... .......... .......... .......... 21%  151M 1s\n",
            " 12350K .......... .......... .......... .......... .......... 21% 67.0M 1s\n",
            " 12400K .......... .......... .......... .......... .......... 21%  150M 1s\n",
            " 12450K .......... .......... .......... .......... .......... 21%  173M 1s\n",
            " 12500K .......... .......... .......... .......... .......... 21%  127M 1s\n",
            " 12550K .......... .......... .......... .......... .......... 22%  145M 1s\n",
            " 12600K .......... .......... .......... .......... .......... 22%  162M 1s\n",
            " 12650K .......... .......... .......... .......... .......... 22%  187M 1s\n",
            " 12700K .......... .......... .......... .......... .......... 22%  169M 1s\n",
            " 12750K .......... .......... .......... .......... .......... 22%  141M 1s\n",
            " 12800K .......... .......... .......... .......... .......... 22%  184M 1s\n",
            " 12850K .......... .......... .......... .......... .......... 22%  197M 1s\n",
            " 12900K .......... .......... .......... .......... .......... 22%  148M 1s\n",
            " 12950K .......... .......... .......... .......... .......... 22%  147M 1s\n",
            " 13000K .......... .......... .......... .......... .......... 22%  191M 1s\n",
            " 13050K .......... .......... .......... .......... .......... 22%  152M 1s\n",
            " 13100K .......... .......... .......... .......... .......... 23%  175M 1s\n",
            " 13150K .......... .......... .......... .......... .......... 23%  139M 1s\n",
            " 13200K .......... .......... .......... .......... .......... 23%  165M 1s\n",
            " 13250K .......... .......... .......... .......... .......... 23%  152M 1s\n",
            " 13300K .......... .......... .......... .......... .......... 23%  124M 1s\n",
            " 13350K .......... .......... .......... .......... .......... 23%  116M 1s\n",
            " 13400K .......... .......... .......... .......... .......... 23%  258M 1s\n",
            " 13450K .......... .......... .......... .......... .......... 23%  259M 1s\n",
            " 13500K .......... .......... .......... .......... .......... 23%  268M 1s\n",
            " 13550K .......... .......... .......... .......... .......... 23%  112M 1s\n",
            " 13600K .......... .......... .......... .......... .......... 23%  165M 1s\n",
            " 13650K .......... .......... .......... .......... .......... 23%  172M 1s\n",
            " 13700K .......... .......... .......... .......... .......... 24%  161M 1s\n",
            " 13750K .......... .......... .......... .......... .......... 24%  140M 1s\n",
            " 13800K .......... .......... .......... .......... .......... 24%  268M 1s\n",
            " 13850K .......... .......... .......... .......... .......... 24%  279M 1s\n",
            " 13900K .......... .......... .......... .......... .......... 24%  248M 1s\n",
            " 13950K .......... .......... .......... .......... .......... 24%  197M 1s\n",
            " 14000K .......... .......... .......... .......... .......... 24%  288M 1s\n",
            " 14050K .......... .......... .......... .......... .......... 24%  233M 1s\n",
            " 14100K .......... .......... .......... .......... .......... 24%  285M 1s\n",
            " 14150K .......... .......... .......... .......... .......... 24%  220M 1s\n",
            " 14200K .......... .......... .......... .......... .......... 24%  245M 1s\n",
            " 14250K .......... .......... .......... .......... .......... 25%  293M 1s\n",
            " 14300K .......... .......... .......... .......... .......... 25%  290M 1s\n",
            " 14350K .......... .......... .......... .......... .......... 25%  201M 1s\n",
            " 14400K .......... .......... .......... .......... .......... 25%  253M 1s\n",
            " 14450K .......... .......... .......... .......... .......... 25%  227M 1s\n",
            " 14500K .......... .......... .......... .......... .......... 25%  261M 1s\n",
            " 14550K .......... .......... .......... .......... .......... 25%  240M 1s\n",
            " 14600K .......... .......... .......... .......... .......... 25%  239M 1s\n",
            " 14650K .......... .......... .......... .......... .......... 25%  256M 1s\n",
            " 14700K .......... .......... .......... .......... .......... 25%  245M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 25%  232M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 26%  288M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 26%  275M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 26%  250M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 26%  104M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 26% 57.8M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 26% 74.0M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 26% 77.7M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 26% 65.8M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 26%  102M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 26%  208M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 26%  192M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 26% 81.9M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 27%  146M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 27%  203M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 27%  285M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 27%  139M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 27%  156M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 27%  180M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 27%  245M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 27%  231M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 27%  181M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 27%  170M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 27%  176M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 28%  136M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 28%  175M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 28%  164M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 28%  165M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 28%  167M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 28%  187M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 28%  178M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 28% 63.8M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 28% 36.6M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 28% 42.1M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 28% 41.3M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 28% 41.8M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 29% 40.4M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 29% 42.9M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 29% 43.0M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 29% 55.3M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 29% 96.7M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 29%  146M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 29% 75.7M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 29%  132M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 29%  133M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 29%  110M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 29%  109M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 30%  208M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 30%  227M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 30%  284M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 30%  271M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 30%  168M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 30%  229M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 30%  294M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 30%  281M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 30%  282M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 30%  151M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 30%  230M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 30%  263M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 31%  184M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 31%  189M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 31%  218M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 31%  190M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 31%  167M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 31%  133M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 31%  167M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 31%  153M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 31%  175M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 31%  160M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 31%  183M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 32%  232M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 32%  131M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 32%  195M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 32%  192M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 32%  199M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 32%  211M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 32%  237M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 32%  266M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 32%  260M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 32%  249M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 32%  162M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 33%  292M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 33%  283M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 33%  275M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 33%  209M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 33%  270M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 33%  286M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 33%  272M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 33%  215M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 33%  282M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 33%  240M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 33%  284M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 33%  272M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 34%  293M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 34%  262M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 34%  257M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 34%  195M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 34%  289M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 34%  298M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 34%  270M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 34%  257M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 34%  223M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 34%  236M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 34%  290M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 35%  221M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 35%  294M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 35%  136M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 35%  184M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 35%  154M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 35%  213M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 35%  280M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 35%  302M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 35%  243M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 35%  269M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 35%  207M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 35%  197M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 36%  133M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 36%  180M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 36%  169M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 36%  190M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 36%  139M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 36%  171M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 36%  175M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 36%  170M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 36%  152M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 36%  178M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 36%  171M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 37%  208M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 37%  205M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 37%  268M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 37%  290M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 37%  299M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 37%  203M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 37%  213M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 37%  287M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 37%  269M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 37%  196M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 37%  154M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 38%  164M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 38%  280M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 38%  261M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 38%  281M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 38%  304M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 38%  205M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 38%  185M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 38%  249M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 38% 29.3M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 38%  173M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 38%  154M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 38% 45.5M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 39%  153M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 39%  171M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 39%  128M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 39%  167M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 39%  176M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 39%  113M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 39% 36.8M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 39% 43.3M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 39% 42.7M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 39% 43.1M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 39% 36.4M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 40% 51.9M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 40%  176M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 40%  180M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 40%  219M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 40%  214M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 40%  176M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 40%  278M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 40%  199M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 40%  187M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 40%  238M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 40%  293M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 40%  177M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 41%  248M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 41%  164M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 41%  212M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 41%  168M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 41%  269M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 41%  242M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 41%  178M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 41%  261M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 41%  242M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 41%  181M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 41%  184M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 42%  207M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 42%  177M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 42%  176M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 42%  239M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 42%  236M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 42%  179M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 42%  216M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 42%  201M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 42%  186M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 42%  181M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 42%  171M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 42%  225M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 43%  224M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 43%  170M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 43%  203M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 43%  178M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 43%  149M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 43%  165M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 43%  114M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 43%  242M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 43%  242M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 43%  199M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 43%  153M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 44%  193M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 44%  140M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 44%  246M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 44%  166M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 44%  187M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 44%  226M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 44%  174M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 44%  170M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 44%  212M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 44%  151M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 44%  158M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 45%  276M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 45%  290M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 45%  160M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 45%  179M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 45%  211M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 45%  296M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 45%  211M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 45%  190M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 45%  204M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 45%  258M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 45%  248M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 45%  277M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 46%  163M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 46% 72.6M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 46%  124M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 46%  183M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 46%  162M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 46%  162M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 46%  163M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 46%  170M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 46%  167M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 46%  172M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 46%  148M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 47%  170M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 47%  158M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 47%  177M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 47%  148M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 47%  176M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 47%  177M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 47%  176M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 47%  200M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 47%  139M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 47%  176M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 47% 85.2M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 47% 68.1M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 48% 80.7M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 48% 94.9M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 48% 47.5M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 48% 93.9M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 48% 71.6M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 48% 41.3M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 48% 43.5M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 48% 43.5M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 48% 80.6M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 48% 76.2M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 48% 80.7M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 49%  122M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 49% 61.7M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 49% 74.5M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 49%  101M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 49% 79.4M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 49%  113M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 49%  158M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 49%  181M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 49%  213M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 49%  280M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 49%  269M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 50%  166M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 50%  236M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 50%  169M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 50%  267M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 50%  221M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 50%  226M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 50%  261M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 50%  251M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 50%  244M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 50%  176M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 50%  255M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 50%  301M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 51%  235M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 51%  223M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 51%  233M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 51%  277M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 51%  183M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 51%  151M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 51%  167M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 51%  232M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 51%  290M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 51%  234M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 51%  108M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 52% 69.0M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 52% 74.1M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 52% 88.1M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 52% 75.7M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 52% 69.3M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 52% 91.0M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 52% 70.2M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 52% 73.9M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 52% 78.7M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 52%  170M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 52%  150M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 52%  173M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 53%  162M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 53%  179M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 53%  138M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 53%  151M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 53%  178M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53%  171M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53%  163M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 53%  171M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 53%  174M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 53%  172M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 53%  133M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 54%  232M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 54%  278M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 54%  297M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 54% 98.2M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 54% 70.8M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 54% 72.9M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 54% 79.4M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 54% 29.5M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 54%  145M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 54%  165M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 54%  179M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 54%  144M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 55%  173M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 55%  173M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 55%  170M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 55%  135M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 55%  170M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 55%  166M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 55% 42.4M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55% 46.1M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55%  128M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55%  102M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55%  149M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56%  149M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56%  169M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56%  177M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56%  180M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56%  154M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56%  167M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56%  191M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56%  181M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56%  141M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56%  169M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56%  189M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57%  170M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57%  152M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57%  163M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57%  151M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57%  160M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57%  147M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57%  171M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57%  173M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57%  180M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57%  162M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57%  158M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57%  170M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58%  185M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58%  148M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58%  157M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58%  166M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58%  173M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58%  139M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58%  178M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58%  178M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58%  175M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58%  149M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58%  172M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59%  154M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59%  166M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59%  152M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59%  189M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59%  165M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59%  169M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59%  131M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59%  177M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59%  169M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59%  170M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59%  158M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59%  173M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60%  179M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60%  178M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60%  146M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60%  165M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60%  184M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60%  167M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60%  139M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60%  176M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60%  176M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60%  171M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60%  150M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61%  179M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61%  176M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61%  170M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61%  166M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61%  170M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61%  181M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61%  183M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61%  136M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61%  160M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61%  164M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61%  170M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61%  153M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62%  166M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62%  169M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62%  168M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62%  145M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62%  169M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62%  179M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62%  164M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62%  161M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62%  171M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62%  158M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62%  171M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63%  148M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63%  179M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63%  138M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63%  162M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63%  165M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63%  185M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63%  172M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63%  184M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63%  146M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63%  146M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63%  174M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64%  175M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64%  147M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64%  171M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64%  184M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64%  174M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64%  131M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64%  180M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64%  169M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64%  172M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64%  160M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64%  177M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64%  118M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65%  159M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65%  135M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65%  157M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65%  170M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65%  175M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65%  158M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65%  172M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65%  189M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65%  174M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65%  137M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65%  174M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66%  175M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66%  177M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66%  137M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66%  179M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66%  174M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66%  180M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66%  146M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66%  161M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66%  175M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  184M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66%  173M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66%  159M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67%  174M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67%  174M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67%  143M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67%  164M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67%  169M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67%  167M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67%  169M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67%  166M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67%  184M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67%  160M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67%  133M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  172M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68%  154M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68%  171M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68%  171M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68%  160M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68%  182M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  173M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68%  148M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68%  162M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68%  167M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68%  181M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69%  153M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69%  162M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69%  165M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69%  171M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69%  145M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69%  134M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69%  172M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69%  170M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69%  160M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69%  179M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69%  169M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69%  174M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70%  144M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70%  171M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70%  178M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70%  179M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70%  170M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70%  167M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70%  180M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70%  170M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70%  138M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70%  175M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70%  178M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71%  180M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71%  156M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71%  169M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71%  176M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71%  163M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71%  143M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71%  179M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71%  181M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71%  170M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71%  153M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71%  180M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71%  174M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72%  151M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72%  138M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72%  175M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72%  163M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72%  170M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72%  163M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72%  152M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72%  173M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72%  171M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72%  137M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72%  163M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73%  181M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73%  141M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73%  153M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73%  108M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73%  144M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73%  123M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73%  139M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73%  163M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73%  147M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73%  147M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73%  145M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73%  136M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74%  168M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74%  182M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74%  135M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74%  174M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74%  180M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74%  169M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74%  157M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74%  170M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74%  162M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74%  164M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74%  147M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75%  179M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75%  166M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75%  165M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75%  153M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75%  171M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75%  165M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75%  173M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75%  144M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75%  159M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75%  169M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75%  176M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76% 87.9M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76%  187M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76%  183M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76%  153M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76%  151M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76%  180M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76%  172M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76%  177M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76%  159M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76%  178M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76%  177M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76%  197M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77%  168M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77% 32.0M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77%  179M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77%  201M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77%  159M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77%  192M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77%  199M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77%  180M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77%  130M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77%  185M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77%  169M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78%  170M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78% 59.6M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78%  167M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78%  163M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78%  176M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78%  133M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78%  176M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78%  197M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78%  191M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78%  137M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78%  180M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78%  187M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79%  161M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79%  134M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79%  183M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79%  163M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79%  174M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79%  164M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79%  189M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79%  176M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79%  177M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79%  165M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79%  173M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80%  174M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80%  184M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80%  144M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80%  162M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80%  180M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80%  167M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80%  140M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80%  201M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80%  208M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80%  155M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80%  137M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81%  173M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81%  160M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81%  159M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81%  145M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81%  167M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81%  156M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81%  171M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81%  159M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81%  151M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81%  157M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81%  199M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81%  167M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82%  186M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82%  181M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82%  187M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82%  152M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82%  166M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82%  180M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82%  187M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82%  142M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82%  177M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82%  206M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82% 64.3M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83%  158M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83%  161M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83%  164M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83%  162M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83%  131M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83%  171M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83%  166M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83%  169M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83%  135M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83%  179M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83%  181M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83%  166M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84%  133M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84%  182M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84%  169M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84%  162M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84%  152M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84%  173M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84%  160M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84%  174M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84%  141M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84%  157M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84%  182M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85%  177M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85%  153M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85%  167M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85%  187M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85%  183M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85%  127M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85%  171M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85%  175M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85%  165M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85%  142M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85%  175M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85%  151M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86%  173M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86%  143M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86%  182M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86%  161M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86%  171M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86%  175M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86%  165M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86%  161M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86%  179M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86%  149M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86%  178M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87%  188M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87%  179M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87%  151M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87%  163M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87%  168M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87%  155M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87%  141M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87%  176M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87%  168M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87%  142M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87%  157M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88%  162M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88%  157M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88%  171M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88%  151M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88%  177M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88%  160M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88%  186M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88%  146M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88%  163M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88%  177M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88%  191M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88%  125M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89%  167M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89%  171M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89%  161M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89%  151M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89%  183M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89%  159M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89%  167M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89%  151M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89%  179M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89%  170M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89%  176M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90%  167M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90%  175M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90%  170M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90%  180M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90%  157M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90%  153M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90%  182M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90%  167M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90%  150M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90%  165M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90%  179M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90%  173M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91%  125M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91%  181M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91%  178M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91%  166M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91%  150M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91%  176M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91%  157M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91%  174M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91%  151M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91%  165M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91%  170M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92%  177M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92%  163M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92%  172M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92%  185M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92%  171M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92%  144M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92%  177M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92%  188M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92%  157M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92%  152M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92%  174M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92%  172M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93%  157M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93%  138M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93%  177M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93%  164M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93%  115M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93%  156M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93%  169M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93%  167M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93%  185M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93%  145M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93%  168M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94%  181M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94%  171M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94%  160M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94%  170M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94%  165M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94%  180M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94%  125M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94%  175M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94%  194M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94%  153M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94%  167M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95%  181M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95%  166M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95%  164M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95%  138M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95%  175M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95%  156M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95%  178M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95%  165M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95%  157M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95%  170M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95%  191M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95%  134M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96%  176M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96%  188M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96%  182M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96%  138M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96%  178M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96%  177M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96%  168M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96%  139M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96%  187M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96%  174M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96%  164M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97%  169M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97%  172M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97%  166M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97%  175M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97%  148M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97%  168M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97%  175M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97%  184M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97%  151M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97%  167M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97%  182M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97%  173M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98%  141M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98%  166M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98%  178M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98%  184M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98%  148M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98%  183M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98%  188M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98%  158M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98%  144M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98%  179M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98%  172M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99%  174M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99%  159M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99%  190M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99%  154M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99%  178M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99%  146M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99%  179M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99%  174M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99%  184M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99%  165M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99%  168M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100%  180M=0.4s\n",
            "\n",
            "2021-06-16 16:40:54 (124 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqnstUezsm6i",
        "outputId": "0bd11a62-2fb1-4ab2-d042-657824038d4a"
      },
      "source": [
        "!which conda # should return /usr/local/bin/conda"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/conda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F5XOnOist9g",
        "outputId": "0304d10c-5ac3-4fc9-8ad2-fdeb2d551ac2"
      },
      "source": [
        "!conda --version # should return 4.5.4"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conda 4.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFVhM1GZswWD",
        "outputId": "94030764-ea3a-49e9-fe4e-02288a1e7300"
      },
      "source": [
        "!which python # still returns /usr/local/bin/python"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "367nafTisye5",
        "outputId": "a930e93b-0ff0-486c-b83b-fb2c0298fc55"
      },
      "source": [
        "!python --version # now returns Python 3.6.5 :: Anaconda, Inc."
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-BFOZszs1nY",
        "outputId": "61f91ab7-b998-4aa3-da2f-6b93b644610d"
      },
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    readline-8.1               |       h27cfd23_0         464 KB\n",
            "    ncurses-6.2                |       he6710b0_1         1.1 MB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    conda-4.10.1               |   py36h06a4308_1         3.1 MB\n",
            "    wheel-0.36.2               |     pyhd3eb1b0_0          31 KB\n",
            "    six-1.16.0                 |     pyhd3eb1b0_0          18 KB\n",
            "    pycosat-0.6.3              |   py36h27cfd23_0         107 KB\n",
            "    pysocks-1.7.1              |   py36h06a4308_0          30 KB\n",
            "    brotlipy-0.7.0             |py36h27cfd23_1003         349 KB\n",
            "    pycparser-2.20             |             py_2          94 KB\n",
            "    setuptools-52.0.0          |   py36h06a4308_0         933 KB\n",
            "    openssl-1.1.1k             |       h27cfd23_0         3.8 MB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    cffi-1.14.5                |   py36h261ae71_0         224 KB\n",
            "    urllib3-1.26.4             |     pyhd3eb1b0_0          99 KB\n",
            "    pip-21.1.2                 |   py36h06a4308_0         2.1 MB\n",
            "    libgomp-9.3.0              |      h5101ec6_17         378 KB\n",
            "    ld_impl_linux-64-2.35.1    |       h7274673_9         637 KB\n",
            "    ruamel_yaml-0.15.100       |   py36h27cfd23_0         268 KB\n",
            "    ca-certificates-2021.5.25  |       h06a4308_1         118 KB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    tk-8.6.10                  |       hbc83047_0         3.2 MB\n",
            "    idna-2.10                  |     pyhd3eb1b0_0          52 KB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    cryptography-3.4.7         |   py36hd23ed53_0         1.0 MB\n",
            "    libstdcxx-ng-9.3.0         |      hd4cf53a_17         4.0 MB\n",
            "    sqlite-3.35.4              |       hdfb4753_0         1.4 MB\n",
            "    _openmp_mutex-4.5          |            1_gnu          22 KB\n",
            "    requests-2.25.1            |     pyhd3eb1b0_0          51 KB\n",
            "    libgcc-ng-9.3.0            |      h5101ec6_17         7.8 MB\n",
            "    pyopenssl-20.0.1           |     pyhd3eb1b0_1          48 KB\n",
            "    conda-package-handling-1.7.3|   py36h27cfd23_1         946 KB\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         141 KB\n",
            "    chardet-4.0.0              |py36h06a4308_1003         213 KB\n",
            "    tqdm-4.59.0                |     pyhd3eb1b0_1          90 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        65.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:          0.1-main               \n",
            "    _openmp_mutex:          4.5-1_gnu              \n",
            "    brotlipy:               0.7.0-py36h27cfd23_1003\n",
            "    conda-package-handling: 1.7.3-py36h27cfd23_1   \n",
            "    ld_impl_linux-64:       2.35.1-h7274673_9      \n",
            "    libgomp:                9.3.0-h5101ec6_17      \n",
            "    tqdm:                   4.59.0-pyhd3eb1b0_1    \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2021.5.25-h06a4308_1    \n",
            "    certifi:                2018.4.16-py36_0        --> 2021.5.30-py36h06a4308_0\n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.5-py36h261ae71_0   \n",
            "    chardet:                3.0.4-py36h0f667ec_1    --> 4.0.0-py36h06a4308_1003 \n",
            "    conda:                  4.5.4-py36_0            --> 4.10.1-py36h06a4308_1   \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 3.4.7-py36hd23ed53_0    \n",
            "    idna:                   2.6-py36h82fb2a8_1      --> 2.10-pyhd3eb1b0_0       \n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.3.0-h5101ec6_17       \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 9.3.0-hd4cf53a_17       \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.2-he6710b0_1          \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1k-h27cfd23_0       \n",
            "    pip:                    10.0.1-py36_0           --> 21.1.2-py36h06a4308_0   \n",
            "    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py36h27cfd23_0    \n",
            "    pycparser:              2.18-py36hf9f622e_1     --> 2.20-py_2               \n",
            "    pyopenssl:              18.0.0-py36_0           --> 20.0.1-pyhd3eb1b0_1     \n",
            "    pysocks:                1.6.8-py36_0            --> 1.7.1-py36h06a4308_0    \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.6.13-h12debd9_1       \n",
            "    readline:               7.0-ha6073c6_4          --> 8.1-h27cfd23_0          \n",
            "    requests:               2.18.4-py36he2e5f8d_1   --> 2.25.1-pyhd3eb1b0_0     \n",
            "    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.100-py36h27cfd23_0 \n",
            "    setuptools:             39.2.0-py36_0           --> 52.0.0-py36h06a4308_0   \n",
            "    six:                    1.11.0-py36h372c433_1   --> 1.16.0-pyhd3eb1b0_0     \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.35.4-hdfb4753_0       \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.10-hbc83047_0       \n",
            "    urllib3:                1.22-py36hbe7ace6_0     --> 1.26.4-pyhd3eb1b0_0     \n",
            "    wheel:                  0.31.1-py36_0           --> 0.36.2-pyhd3eb1b0_0     \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7b6447c_0        \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0        \n",
            "    zlib:                   1.2.11-ha838bed_2       --> 1.2.11-h7b6447c_3       \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  asn1crypto-0.24.0-py36_0\n",
            "  conda-env-2.6.0-h36134e3_1\n",
            "  libedit-3.1.20170329-h6b74fdf_2\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rreadline-8.1         |  464 KB |            |   0% \rreadline-8.1         |  464 KB | ########9  |  90% \rreadline-8.1         |  464 KB | ########## | 100% \n",
            "\rncurses-6.2          |  1.1 MB |            |   0% \rncurses-6.2          |  1.1 MB | #######8   |  78% \rncurses-6.2          |  1.1 MB | #########9 | 100% \rncurses-6.2          |  1.1 MB | ########## | 100% \n",
            "\rxz-5.2.5             |  438 KB |            |   0% \rxz-5.2.5             |  438 KB | #########  |  90% \rxz-5.2.5             |  438 KB | ########## | 100% \n",
            "\rconda-4.10.1         |  3.1 MB |            |   0% \rconda-4.10.1         |  3.1 MB | #######6   |  77% \rconda-4.10.1         |  3.1 MB | ########9  |  90% \rconda-4.10.1         |  3.1 MB | #########9 | 100% \rconda-4.10.1         |  3.1 MB | ########## | 100% \n",
            "\rwheel-0.36.2         |   31 KB |            |   0% \rwheel-0.36.2         |   31 KB | ########## | 100% \n",
            "\rsix-1.16.0           |   18 KB |            |   0% \rsix-1.16.0           |   18 KB | ########## | 100% \n",
            "\rpycosat-0.6.3        |  107 KB |            |   0% \rpycosat-0.6.3        |  107 KB | ########## | 100% \n",
            "\rpysocks-1.7.1        |   30 KB |            |   0% \rpysocks-1.7.1        |   30 KB | ########## | 100% \n",
            "\rbrotlipy-0.7.0       |  349 KB |            |   0% \rbrotlipy-0.7.0       |  349 KB | ########## | 100% \n",
            "\rpycparser-2.20       |   94 KB |            |   0% \rpycparser-2.20       |   94 KB | ########## | 100% \n",
            "\rsetuptools-52.0.0    |  933 KB |            |   0% \rsetuptools-52.0.0    |  933 KB | ########1  |  81% \rsetuptools-52.0.0    |  933 KB | #########9 | 100% \rsetuptools-52.0.0    |  933 KB | ########## | 100% \n",
            "\ropenssl-1.1.1k       |  3.8 MB |            |   0% \ropenssl-1.1.1k       |  3.8 MB | #######5   |  75% \ropenssl-1.1.1k       |  3.8 MB | #########7 |  98% \ropenssl-1.1.1k       |  3.8 MB | ########## | 100% \n",
            "\ryaml-0.2.5           |   87 KB |            |   0% \ryaml-0.2.5           |   87 KB | ########## | 100% \n",
            "\r_libgcc_mutex-0.1    |    3 KB |            |   0% \r_libgcc_mutex-0.1    |    3 KB | ########## | 100% \n",
            "\rcffi-1.14.5          |  224 KB |            |   0% \rcffi-1.14.5          |  224 KB | ########## | 100% \n",
            "\rurllib3-1.26.4       |   99 KB |            |   0% \rurllib3-1.26.4       |   99 KB | ########## | 100% \n",
            "\rpip-21.1.2           |  2.1 MB |            |   0% \rpip-21.1.2           |  2.1 MB | #######7   |  78% \rpip-21.1.2           |  2.1 MB | #########  |  91% \rpip-21.1.2           |  2.1 MB | ########## | 100% \n",
            "\rlibgomp-9.3.0        |  378 KB |            |   0% \rlibgomp-9.3.0        |  378 KB | #########7 |  98% \rlibgomp-9.3.0        |  378 KB | ########## | 100% \n",
            "\rld_impl_linux-64-2.3 |  637 KB |            |   0% \rld_impl_linux-64-2.3 |  637 KB | #########1 |  92% \rld_impl_linux-64-2.3 |  637 KB | ########## | 100% \n",
            "\rruamel_yaml-0.15.100 |  268 KB |            |   0% \rruamel_yaml-0.15.100 |  268 KB | ########## | 100% \n",
            "\rca-certificates-2021 |  118 KB |            |   0% \rca-certificates-2021 |  118 KB | ########## | 100% \n",
            "\rzlib-1.2.11          |  120 KB |            |   0% \rzlib-1.2.11          |  120 KB | ########## | 100% \n",
            "\rlibffi-3.3           |   54 KB |            |   0% \rlibffi-3.3           |   54 KB | ########## | 100% \n",
            "\rtk-8.6.10            |  3.2 MB |            |   0% \rtk-8.6.10            |  3.2 MB | #######7   |  78% \rtk-8.6.10            |  3.2 MB | #########8 |  98% \rtk-8.6.10            |  3.2 MB | ########## | 100% \n",
            "\ridna-2.10            |   52 KB |            |   0% \ridna-2.10            |   52 KB | ########## | 100% \n",
            "\rpython-3.6.13        | 32.5 MB |            |   0% \rpython-3.6.13        | 32.5 MB | #8         |  18% \rpython-3.6.13        | 32.5 MB | #####      |  51% \rpython-3.6.13        | 32.5 MB | #######5   |  75% \rpython-3.6.13        | 32.5 MB | #########1 |  92% \rpython-3.6.13        | 32.5 MB | ########## | 100% \n",
            "\rcryptography-3.4.7   |  1.0 MB |            |   0% \rcryptography-3.4.7   |  1.0 MB | #######9   |  80% \rcryptography-3.4.7   |  1.0 MB | #########5 |  96% \rcryptography-3.4.7   |  1.0 MB | ########## | 100% \n",
            "\rlibstdcxx-ng-9.3.0   |  4.0 MB |            |   0% \rlibstdcxx-ng-9.3.0   |  4.0 MB | #######6   |  77% \rlibstdcxx-ng-9.3.0   |  4.0 MB | #########5 |  96% \rlibstdcxx-ng-9.3.0   |  4.0 MB | ########## | 100% \n",
            "\rsqlite-3.35.4        |  1.4 MB |            |   0% \rsqlite-3.35.4        |  1.4 MB | #######9   |  79% \rsqlite-3.35.4        |  1.4 MB | ########## | 100% \n",
            "\r_openmp_mutex-4.5    |   22 KB |            |   0% \r_openmp_mutex-4.5    |   22 KB | ########## | 100% \n",
            "\rrequests-2.25.1      |   51 KB |            |   0% \rrequests-2.25.1      |   51 KB | ########## | 100% \n",
            "\rlibgcc-ng-9.3.0      |  7.8 MB |            |   0% \rlibgcc-ng-9.3.0      |  7.8 MB | #######5   |  75% \rlibgcc-ng-9.3.0      |  7.8 MB | #########7 |  98% \rlibgcc-ng-9.3.0      |  7.8 MB | ########## | 100% \n",
            "\rpyopenssl-20.0.1     |   48 KB |            |   0% \rpyopenssl-20.0.1     |   48 KB | ########## | 100% \n",
            "\rconda-package-handli |  946 KB |            |   0% \rconda-package-handli |  946 KB | ########6  |  86% \rconda-package-handli |  946 KB | ########## | 100% \n",
            "\rcertifi-2021.5.30    |  141 KB |            |   0% \rcertifi-2021.5.30    |  141 KB | ########## | 100% \n",
            "\rchardet-4.0.0        |  213 KB |            |   0% \rchardet-4.0.0        |  213 KB | #########8 |  98% \rchardet-4.0.0        |  213 KB | ########## | 100% \n",
            "\rtqdm-4.59.0          |   90 KB |            |   0% \rtqdm-4.59.0          |   90 KB | ########## | 100% \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_8u9kFYs5E_",
        "outputId": "02e5dc56-e98c-4308-bcf8-98ce14da36a7"
      },
      "source": [
        "!conda --version # now returns 4.8.3"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conda 4.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39TB_M6vtKD_",
        "outputId": "42db1814-e721-47e1-cdde-5cffc79b791e"
      },
      "source": [
        "!python --version # now returns Python 3.6.10 :: Anaconda, Inc."
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.13 :: Anaconda, Inc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldnv2cBptMzB",
        "outputId": "e5dc58e4-8217-415c-cf79-e91d8ffb4786"
      },
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eClEI69QtQz_",
        "outputId": "17d3f1a4-f21d-4855-ba5d-ff7219abfde3"
      },
      "source": [
        "['',  \n",
        " '/env/python',\n",
        " '/usr/lib/python36.zip',\n",
        " '/usr/lib/python3.6',\n",
        " '/usr/lib/python3.6/lib-dynload',\n",
        " '/usr/local/lib/python3.6/dist-packages', # pre-installed packages\n",
        " '/usr/lib/python3/dist-packages',\n",
        " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
        " '/root/.ipython']"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJX_5o9btToZ"
      },
      "source": [
        "!ls /usr/local/lib/python3.6/dist-packages"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4aUxWs3tVoz"
      },
      "source": [
        "import sys\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.6/site-packages\"))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rwu0D_cntXuK",
        "outputId": "834e7b05-a4e8-4feb-a181-e9bba5fc8277"
      },
      "source": [
        "!conda install --channel conda-forge featuretools --yes"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - featuretools\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bokeh-2.3.2                |   py36h5fab9bb_0         8.3 MB  conda-forge\n",
            "    ca-certificates-2021.5.30  |       ha878542_0         136 KB  conda-forge\n",
            "    certifi-2021.5.30          |   py36h5fab9bb_0         141 KB  conda-forge\n",
            "    click-7.1.2                |     pyh9f0ad1d_0          64 KB  conda-forge\n",
            "    cloudpickle-1.6.0          |             py_0          22 KB  conda-forge\n",
            "    conda-4.10.1               |   py36h5fab9bb_0         3.1 MB  conda-forge\n",
            "    contextvars-2.4            |             py_0          11 KB  conda-forge\n",
            "    cytoolz-0.11.0             |   py36h8f6f2f9_3         393 KB  conda-forge\n",
            "    dask-2021.3.0              |     pyhd8ed1ab_0           4 KB  conda-forge\n",
            "    dask-core-2021.3.0         |     pyhd8ed1ab_0         702 KB  conda-forge\n",
            "    distributed-2021.3.0       |   py36h5fab9bb_0         1.1 MB  conda-forge\n",
            "    featuretools-0.23.3        |     pyhd8ed1ab_0         267 KB  conda-forge\n",
            "    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n",
            "    fsspec-2021.6.0            |     pyhd8ed1ab_0          79 KB  conda-forge\n",
            "    heapdict-1.0.1             |             py_0           7 KB  conda-forge\n",
            "    immutables-0.15            |   py36h8f6f2f9_0          70 KB  conda-forge\n",
            "    jbig-2.1                   |    h7f98852_2003          43 KB  conda-forge\n",
            "    jinja2-3.0.1               |     pyhd8ed1ab_0          99 KB  conda-forge\n",
            "    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n",
            "    lcms2-2.12                 |       hddcbb42_0         443 KB  conda-forge\n",
            "    lerc-2.2.1                 |       h9c3ff4c_0         213 KB  conda-forge\n",
            "    libblas-3.9.0              |       9_openblas          11 KB  conda-forge\n",
            "    libcblas-3.9.0             |       9_openblas          11 KB  conda-forge\n",
            "    libdeflate-1.7             |       h7f98852_5          67 KB  conda-forge\n",
            "    libgfortran-ng-9.3.0       |      hff62375_19          22 KB  conda-forge\n",
            "    libgfortran5-9.3.0         |      hff62375_19         2.0 MB  conda-forge\n",
            "    liblapack-3.9.0            |       9_openblas          11 KB  conda-forge\n",
            "    libopenblas-0.3.15         |pthreads_h8fe5266_1         9.2 MB  conda-forge\n",
            "    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n",
            "    libtiff-4.3.0              |       hf544144_1         668 KB  conda-forge\n",
            "    libwebp-base-1.2.0         |       h7f98852_2         815 KB  conda-forge\n",
            "    locket-0.2.0               |             py_2           6 KB  conda-forge\n",
            "    lz4-c-1.9.3                |       h9c3ff4c_0         179 KB  conda-forge\n",
            "    markupsafe-2.0.1           |   py36h8f6f2f9_0          22 KB  conda-forge\n",
            "    msgpack-python-1.0.2       |   py36h605e78d_1          91 KB  conda-forge\n",
            "    numpy-1.19.5               |   py36h2aa4a07_1         5.3 MB  conda-forge\n",
            "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
            "    openjpeg-2.4.0             |       hb52868f_1         444 KB  conda-forge\n",
            "    openssl-1.1.1k             |       h7f98852_0         2.1 MB  conda-forge\n",
            "    packaging-20.9             |     pyh44b312d_0          35 KB  conda-forge\n",
            "    pandas-1.1.5               |   py36h284efc9_0        11.3 MB  conda-forge\n",
            "    partd-1.2.0                |     pyhd8ed1ab_0          18 KB  conda-forge\n",
            "    pillow-8.2.0               |   py36ha6010c0_1         688 KB  conda-forge\n",
            "    psutil-5.8.0               |   py36h8f6f2f9_1         342 KB  conda-forge\n",
            "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n",
            "    pytz-2021.1                |     pyhd8ed1ab_0         239 KB  conda-forge\n",
            "    pyyaml-5.4.1               |   py36h8f6f2f9_0         190 KB  conda-forge\n",
            "    scipy-1.5.3                |   py36h9e8f40b_0        19.1 MB  conda-forge\n",
            "    sortedcontainers-2.4.0     |     pyhd8ed1ab_0          26 KB  conda-forge\n",
            "    tblib-1.7.0                |     pyhd8ed1ab_0          15 KB  conda-forge\n",
            "    toolz-0.11.1               |             py_0          46 KB  conda-forge\n",
            "    tornado-6.1                |   py36h8f6f2f9_1         643 KB  conda-forge\n",
            "    typing_extensions-3.10.0.0 |     pyha770c72_0          28 KB  conda-forge\n",
            "    zict-2.0.0                 |             py_0          10 KB  conda-forge\n",
            "    zstd-1.5.0                 |       ha95c52a_0         490 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        70.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  bokeh              conda-forge/linux-64::bokeh-2.3.2-py36h5fab9bb_0\n",
            "  click              conda-forge/noarch::click-7.1.2-pyh9f0ad1d_0\n",
            "  cloudpickle        conda-forge/noarch::cloudpickle-1.6.0-py_0\n",
            "  contextvars        conda-forge/noarch::contextvars-2.4-py_0\n",
            "  cytoolz            conda-forge/linux-64::cytoolz-0.11.0-py36h8f6f2f9_3\n",
            "  dask               conda-forge/noarch::dask-2021.3.0-pyhd8ed1ab_0\n",
            "  dask-core          conda-forge/noarch::dask-core-2021.3.0-pyhd8ed1ab_0\n",
            "  distributed        conda-forge/linux-64::distributed-2021.3.0-py36h5fab9bb_0\n",
            "  featuretools       conda-forge/noarch::featuretools-0.23.3-pyhd8ed1ab_0\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
            "  fsspec             conda-forge/noarch::fsspec-2021.6.0-pyhd8ed1ab_0\n",
            "  heapdict           conda-forge/noarch::heapdict-1.0.1-py_0\n",
            "  immutables         conda-forge/linux-64::immutables-0.15-py36h8f6f2f9_0\n",
            "  jbig               conda-forge/linux-64::jbig-2.1-h7f98852_2003\n",
            "  jinja2             conda-forge/noarch::jinja2-3.0.1-pyhd8ed1ab_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n",
            "  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\n",
            "  lerc               conda-forge/linux-64::lerc-2.2.1-h9c3ff4c_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-9_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-9_openblas\n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.7-h7f98852_5\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-9.3.0-hff62375_19\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-9.3.0-hff62375_19\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-9_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.15-pthreads_h8fe5266_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.3.0-hf544144_1\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.2.0-h7f98852_2\n",
            "  locket             conda-forge/noarch::locket-0.2.0-py_2\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_0\n",
            "  markupsafe         conda-forge/linux-64::markupsafe-2.0.1-py36h8f6f2f9_0\n",
            "  msgpack-python     conda-forge/linux-64::msgpack-python-1.0.2-py36h605e78d_1\n",
            "  numpy              conda-forge/linux-64::numpy-1.19.5-py36h2aa4a07_1\n",
            "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hb52868f_1\n",
            "  packaging          conda-forge/noarch::packaging-20.9-pyh44b312d_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.1.5-py36h284efc9_0\n",
            "  partd              conda-forge/noarch::partd-1.2.0-pyhd8ed1ab_0\n",
            "  pillow             conda-forge/linux-64::pillow-8.2.0-py36ha6010c0_1\n",
            "  psutil             conda-forge/linux-64::psutil-5.8.0-py36h8f6f2f9_1\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.6-1_cp36m\n",
            "  pytz               conda-forge/noarch::pytz-2021.1-pyhd8ed1ab_0\n",
            "  pyyaml             conda-forge/linux-64::pyyaml-5.4.1-py36h8f6f2f9_0\n",
            "  scipy              conda-forge/linux-64::scipy-1.5.3-py36h9e8f40b_0\n",
            "  sortedcontainers   conda-forge/noarch::sortedcontainers-2.4.0-pyhd8ed1ab_0\n",
            "  tblib              conda-forge/noarch::tblib-1.7.0-pyhd8ed1ab_0\n",
            "  toolz              conda-forge/noarch::toolz-0.11.1-py_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.1-py36h8f6f2f9_1\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-3.10.0.0-pyha770c72_0\n",
            "  zict               conda-forge/noarch::zict-2.0.0-py_0\n",
            "  zstd               conda-forge/linux-64::zstd-1.5.0-ha95c52a_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2021.5.25-~ --> conda-forge::ca-certificates-2021.5.30-ha878542_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  certifi            pkgs/main::certifi-2021.5.30-py36h06a~ --> conda-forge::certifi-2021.5.30-py36h5fab9bb_0\n",
            "  conda              pkgs/main::conda-4.10.1-py36h06a4308_1 --> conda-forge::conda-4.10.1-py36h5fab9bb_0\n",
            "  openssl              pkgs/main::openssl-1.1.1k-h27cfd23_0 --> conda-forge::openssl-1.1.1k-h7f98852_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "psutil-5.8.0         | 342 KB    | : 100% 1.0/1 [00:00<00:00,  4.66it/s]\n",
            "packaging-20.9       | 35 KB     | : 100% 1.0/1 [00:00<00:00, 23.45it/s]\n",
            "pillow-8.2.0         | 688 KB    | : 100% 1.0/1 [00:00<00:00,  5.04it/s]\n",
            "cytoolz-0.11.0       | 393 KB    | : 100% 1.0/1 [00:00<00:00,  7.71it/s]\n",
            "pyparsing-2.4.7      | 60 KB     | : 100% 1.0/1 [00:00<00:00, 18.71it/s]\n",
            "lcms2-2.12           | 443 KB    | : 100% 1.0/1 [00:00<00:00,  8.34it/s]\n",
            "libtiff-4.3.0        | 668 KB    | : 100% 1.0/1 [00:00<00:00,  5.73it/s]\n",
            "libwebp-base-1.2.0   | 815 KB    | : 100% 1.0/1 [00:00<00:00,  5.17it/s]\n",
            "cloudpickle-1.6.0    | 22 KB     | : 100% 1.0/1 [00:00<00:00, 23.70it/s]\n",
            "freetype-2.10.4      | 890 KB    | : 100% 1.0/1 [00:00<00:00,  4.40it/s]\n",
            "openjpeg-2.4.0       | 444 KB    | : 100% 1.0/1 [00:00<00:00,  7.63it/s]\n",
            "lerc-2.2.1           | 213 KB    | : 100% 1.0/1 [00:00<00:00, 12.51it/s]\n",
            "libpng-1.6.37        | 306 KB    | : 100% 1.0/1 [00:00<00:00,  9.36it/s]\n",
            "locket-0.2.0         | 6 KB      | : 100% 1.0/1 [00:00<00:00, 24.14it/s]\n",
            "numpy-1.19.5         | 5.3 MB    | : 100% 1.0/1 [00:01<00:00,  1.34s/it]\n",
            "conda-4.10.1         | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.43it/s]\n",
            "openssl-1.1.1k       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.55it/s]\n",
            "tornado-6.1          | 643 KB    | : 100% 1.0/1 [00:00<00:00,  4.38it/s]\n",
            "distributed-2021.3.0 | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.63it/s]\n",
            "jbig-2.1             | 43 KB     | : 100% 1.0/1 [00:00<00:00, 18.56it/s]\n",
            "python_abi-3.6       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 12.54it/s]\n",
            "featuretools-0.23.3  | 267 KB    | : 100% 1.0/1 [00:00<00:00,  5.58it/s]\n",
            "libdeflate-1.7       | 67 KB     | : 100% 1.0/1 [00:00<00:00, 17.74it/s]\n",
            "immutables-0.15      | 70 KB     | : 100% 1.0/1 [00:00<00:00, 13.97it/s]\n",
            "heapdict-1.0.1       | 7 KB      | : 100% 1.0/1 [00:00<00:00, 22.64it/s]\n",
            "certifi-2021.5.30    | 141 KB    | : 100% 1.0/1 [00:00<00:00, 14.06it/s]\n",
            "ca-certificates-2021 | 136 KB    | : 100% 1.0/1 [00:00<00:00, 17.81it/s]\n",
            "markupsafe-2.0.1     | 22 KB     | : 100% 1.0/1 [00:00<00:00, 24.90it/s]\n",
            "sortedcontainers-2.4 | 26 KB     | : 100% 1.0/1 [00:00<00:00, 19.35it/s]\n",
            "zstd-1.5.0           | 490 KB    | : 100% 1.0/1 [00:00<00:00,  6.37it/s]\n",
            "pyyaml-5.4.1         | 190 KB    | : 100% 1.0/1 [00:00<00:00, 12.18it/s]\n",
            "tblib-1.7.0          | 15 KB     | : 100% 1.0/1 [00:00<00:00, 27.22it/s]\n",
            "libblas-3.9.0        | 11 KB     | : 100% 1.0/1 [00:00<00:00, 23.31it/s]\n",
            "partd-1.2.0          | 18 KB     | : 100% 1.0/1 [00:00<00:00, 24.73it/s]\n",
            "pytz-2021.1          | 239 KB    | : 100% 1.0/1 [00:00<00:00,  6.90it/s]\n",
            "pandas-1.1.5         | 11.3 MB   | : 100% 1.0/1 [00:02<00:00,  3.00s/it]\n",
            "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 23.32it/s]\n",
            "msgpack-python-1.0.2 | 91 KB     | : 100% 1.0/1 [00:00<00:00, 18.09it/s]\n",
            "libopenblas-0.3.15   | 9.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.87s/it]\n",
            "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 17.52it/s]\n",
            "contextvars-2.4      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 28.23it/s]\n",
            "bokeh-2.3.2          | 8.3 MB    | : 100% 1.0/1 [00:02<00:00,  2.63s/it]               \n",
            "jpeg-9d              | 264 KB    | : 100% 1.0/1 [00:00<00:00,  9.53it/s]\n",
            "python-dateutil-2.8. | 220 KB    | : 100% 1.0/1 [00:00<00:00, 13.62it/s]\n",
            "libgfortran-ng-9.3.0 | 22 KB     | : 100% 1.0/1 [00:00<00:00, 26.61it/s]\n",
            "zict-2.0.0           | 10 KB     | : 100% 1.0/1 [00:00<00:00, 22.50it/s]\n",
            "toolz-0.11.1         | 46 KB     | : 100% 1.0/1 [00:00<00:00, 17.95it/s]\n",
            "lz4-c-1.9.3          | 179 KB    | : 100% 1.0/1 [00:00<00:00, 14.00it/s]\n",
            "typing_extensions-3. | 28 KB     | : 100% 1.0/1 [00:00<00:00, 24.26it/s]\n",
            "dask-2021.3.0        | 4 KB      | : 100% 1.0/1 [00:00<00:00, 26.72it/s]\n",
            "dask-core-2021.3.0   | 702 KB    | : 100% 1.0/1 [00:00<00:00,  4.02it/s]\n",
            "libgfortran5-9.3.0   | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  2.17it/s]\n",
            "scipy-1.5.3          | 19.1 MB   | : 100% 1.0/1 [00:03<00:00,  3.88s/it]\n",
            "olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 23.06it/s]\n",
            "click-7.1.2          | 64 KB     | : 100% 1.0/1 [00:00<00:00, 17.92it/s]\n",
            "jinja2-3.0.1         | 99 KB     | : 100% 1.0/1 [00:00<00:00, 15.13it/s]\n",
            "fsspec-2021.6.0      | 79 KB     | : 100% 1.0/1 [00:00<00:00, 14.07it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpaqlERWtZwA",
        "outputId": "99abfb76-a9b1-41e3-9e16-3dbf0f923006"
      },
      "source": [
        "!conda install pytorch=0.4.1 torchvision=0.2.1 -c pytorch\n",
        "!pip install tensorboardX==1.4\n",
        "!conda install opencv=3.3.1   # just needed for evaluation"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytorch=0.4.1\n",
            "    - torchvision=0.2.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         139 KB\n",
            "    conda-4.10.1               |   py36h06a4308_1         2.9 MB\n",
            "    intel-openmp-2021.2.0      |     h06a4308_610         1.3 MB\n",
            "    mkl-2021.2.0               |     h06a4308_296       144.3 MB\n",
            "    ninja-1.10.2               |       hff7bd54_1         1.4 MB\n",
            "    pytorch-0.4.1              |py36_py35_py27__9.0.176_7.1.2_2       471.7 MB  pytorch\n",
            "    torchvision-0.2.1          |             py_2          37 KB  pytorch\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       621.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.2.0-h06a4308_610\n",
            "  mkl                pkgs/main/linux-64::mkl-2021.2.0-h06a4308_296\n",
            "  ninja              pkgs/main/linux-64::ninja-1.10.2-hff7bd54_1\n",
            "  pytorch            pytorch/linux-64::pytorch-0.4.1-py36_py35_py27__9.0.176_7.1.2_2\n",
            "  torchvision        pytorch/noarch::torchvision-0.2.1-py_2\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda              conda-forge::conda-4.10.1-py36h5fab9b~ --> pkgs/main::conda-4.10.1-py36h06a4308_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  certifi            conda-forge::certifi-2021.5.30-py36h5~ --> pkgs/main::certifi-2021.5.30-py36h06a4308_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "certifi-2021.5.30    | 139 KB    | : 100% 1.0/1 [00:00<00:00,  8.72it/s]\n",
            "torchvision-0.2.1    | 37 KB     | : 100% 1.0/1 [00:00<00:00,  1.14it/s]               \n",
            "pytorch-0.4.1        | 471.7 MB  | : 100% 1.0/1 [01:22<00:00, 82.25s/it]               \n",
            "intel-openmp-2021.2. | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  7.35it/s]\n",
            "ninja-1.10.2         | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  7.39it/s]\n",
            "mkl-2021.2.0         | 144.3 MB  | : 100% 1.0/1 [00:07<00:00,  7.33s/it]               \n",
            "conda-4.10.1         | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  3.91it/s]\n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Collecting tensorboardX==1.4\n",
            "  Using cached tensorboardX-1.4-py2.py3-none-any.whl (67 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from tensorboardX==1.4) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from tensorboardX==1.4) (1.16.0)\n",
            "Collecting protobuf>=3.2.0\n",
            "  Downloading protobuf-3.17.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 9.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: protobuf, tensorboardX\n",
            "Successfully installed protobuf-3.17.3 tensorboardX-1.4\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - opencv=3.3.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |         openblas          46 KB\n",
            "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
            "    cairo-1.16.0               |       hf32fb01_1         1.0 MB\n",
            "    ffmpeg-3.4                 |       h7985aa0_0         7.1 MB\n",
            "    fontconfig-2.13.1          |       h6c09931_0         250 KB\n",
            "    glib-2.68.2                |       h36276a3_0         3.0 MB\n",
            "    graphite2-1.3.14           |       h23475e2_0          99 KB\n",
            "    harfbuzz-1.8.8             |       hffaf4a1_0         507 KB\n",
            "    hdf5-1.10.1                |       h9caa474_1         3.8 MB\n",
            "    icu-58.2                   |       he6710b0_3        10.5 MB\n",
            "    jasper-1.900.1             |       hd497a04_4         198 KB\n",
            "    libgfortran-ng-7.5.0       |      ha8ba4b0_17          22 KB\n",
            "    libgfortran4-7.5.0         |      ha8ba4b0_17         995 KB\n",
            "    libopenblas-0.3.13         |       h4367d64_0         4.8 MB\n",
            "    libopus-1.3.1              |       h7b6447c_0         491 KB\n",
            "    libprotobuf-3.4.1          |       h5b8497f_0         2.4 MB\n",
            "    libuuid-1.0.3              |       h1bed415_2          15 KB\n",
            "    libvpx-1.7.0               |       h439df22_0         1.2 MB\n",
            "    libxcb-1.14                |       h7b6447c_0         505 KB\n",
            "    libxml2-2.9.10             |       hb55368b_3         1.2 MB\n",
            "    numpy-1.19.2               |   py36h6163131_0          22 KB\n",
            "    numpy-base-1.19.2          |   py36h75fe3a5_0         4.1 MB\n",
            "    opencv-3.3.1               |   py36h6cbbc71_1        21.2 MB\n",
            "    pcre-8.44                  |       he6710b0_0         212 KB\n",
            "    pixman-0.40.0              |       h7b6447c_0         370 KB\n",
            "    scipy-1.5.2                |   py36habc2bb6_0        14.3 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        78.5 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-openblas\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  cairo              pkgs/main/linux-64::cairo-1.16.0-hf32fb01_1\n",
            "  ffmpeg             pkgs/main/linux-64::ffmpeg-3.4-h7985aa0_0\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.1-h6c09931_0\n",
            "  glib               pkgs/main/linux-64::glib-2.68.2-h36276a3_0\n",
            "  graphite2          pkgs/main/linux-64::graphite2-1.3.14-h23475e2_0\n",
            "  harfbuzz           pkgs/main/linux-64::harfbuzz-1.8.8-hffaf4a1_0\n",
            "  hdf5               pkgs/main/linux-64::hdf5-1.10.1-h9caa474_1\n",
            "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
            "  jasper             pkgs/main/linux-64::jasper-1.900.1-hd497a04_4\n",
            "  libgfortran4       pkgs/main/linux-64::libgfortran4-7.5.0-ha8ba4b0_17\n",
            "  libopus            pkgs/main/linux-64::libopus-1.3.1-h7b6447c_0\n",
            "  libprotobuf        pkgs/main/linux-64::libprotobuf-3.4.1-h5b8497f_0\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
            "  libvpx             pkgs/main/linux-64::libvpx-1.7.0-h439df22_0\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.10-hb55368b_3\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.2-py36h75fe3a5_0\n",
            "  opencv             pkgs/main/linux-64::opencv-3.3.1-py36h6cbbc71_1\n",
            "  pcre               pkgs/main/linux-64::pcre-8.44-he6710b0_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7b6447c_0\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  libblas-3.9.0-9_openblas\n",
            "  libcblas-3.9.0-9_openblas\n",
            "  libgfortran5-9.3.0-hff62375_19\n",
            "  liblapack-3.9.0-9_openblas\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2021.5.3~ --> pkgs/main::ca-certificates-2021.5.25-h06a4308_1\n",
            "  libgfortran-ng     conda-forge::libgfortran-ng-9.3.0-hff~ --> pkgs/main::libgfortran-ng-7.5.0-ha8ba4b0_17\n",
            "  libopenblas        conda-forge::libopenblas-0.3.15-pthre~ --> pkgs/main::libopenblas-0.3.13-h4367d64_0\n",
            "  numpy              conda-forge::numpy-1.19.5-py36h2aa4a0~ --> pkgs/main::numpy-1.19.2-py36h6163131_0\n",
            "  openssl            conda-forge::openssl-1.1.1k-h7f98852_0 --> pkgs/main::openssl-1.1.1k-h27cfd23_0\n",
            "  scipy              conda-forge::scipy-1.5.3-py36h9e8f40b~ --> pkgs/main::scipy-1.5.2-py36habc2bb6_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "fontconfig-2.13.1    | 250 KB    | : 100% 1.0/1 [00:00<00:00,  5.99it/s]                \n",
            "icu-58.2             | 10.5 MB   | : 100% 1.0/1 [00:00<00:00,  2.25it/s]\n",
            "glib-2.68.2          | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  5.48it/s]\n",
            "libopus-1.3.1        | 491 KB    | : 100% 1.0/1 [00:00<00:00, 11.56it/s]\n",
            "libvpx-1.7.0         | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  8.00it/s]\n",
            "scipy-1.5.2          | 14.3 MB   | : 100% 1.0/1 [00:00<00:00,  1.45it/s]\n",
            "numpy-base-1.19.2    | 4.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.46it/s]\n",
            "pixman-0.40.0        | 370 KB    | : 100% 1.0/1 [00:00<00:00, 13.46it/s]\n",
            "libxml2-2.9.10       | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  6.53it/s]\n",
            "libopenblas-0.3.13   | 4.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.01it/s]\n",
            "libprotobuf-3.4.1    | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  6.03it/s]\n",
            "hdf5-1.10.1          | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.35it/s]\n",
            "blas-1.0             | 46 KB     | : 100% 1.0/1 [00:00<00:00, 13.24it/s]\n",
            "bzip2-1.0.8          | 78 KB     | : 100% 1.0/1 [00:00<00:00, 16.07it/s]\n",
            "pcre-8.44            | 212 KB    | : 100% 1.0/1 [00:00<00:00, 15.62it/s]\n",
            "libgfortran-ng-7.5.0 | 22 KB     | : 100% 1.0/1 [00:00<00:00, 17.31it/s]\n",
            "opencv-3.3.1         | 21.2 MB   | : 100% 1.0/1 [00:01<00:00,  1.71s/it]               \n",
            "numpy-1.19.2         | 22 KB     | : 100% 1.0/1 [00:00<00:00, 13.67it/s]\n",
            "libxcb-1.14          | 505 KB    | : 100% 1.0/1 [00:00<00:00, 11.00it/s]\n",
            "harfbuzz-1.8.8       | 507 KB    | : 100% 1.0/1 [00:00<00:00, 10.02it/s]\n",
            "graphite2-1.3.14     | 99 KB     | : 100% 1.0/1 [00:00<00:00, 13.88it/s]\n",
            "jasper-1.900.1       | 198 KB    | : 100% 1.0/1 [00:00<00:00, 11.13it/s]\n",
            "libuuid-1.0.3        | 15 KB     | : 100% 1.0/1 [00:00<00:00, 15.89it/s]\n",
            "libgfortran4-7.5.0   | 995 KB    | : 100% 1.0/1 [00:00<00:00, 10.16it/s]\n",
            "ffmpeg-3.4           | 7.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.70it/s]\n",
            "cairo-1.16.0         | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  7.04it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNA23_5jub_4",
        "outputId": "3684c6f3-6eb1-41e5-d5b3-2afdf17715a9"
      },
      "source": [
        "!conda install pytorch torchvision opencv\n",
        "!pip install timm"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "Collecting timm\n",
            "  Downloading timm-0.4.9-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/site-packages (from timm) (0.2.1)\n",
            "Collecting torch>=1.4\n",
            "  Downloading torch-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 10 kB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/site-packages (from torch>=1.4->timm) (3.10.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from torchvision->timm) (1.19.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/site-packages (from torchvision->timm) (8.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from torchvision->timm) (1.16.0)\n",
            "Installing collected packages: dataclasses, torch, timm\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 0.4.1.post2\n",
            "    Uninstalling torch-0.4.1.post2:\n",
            "      Successfully uninstalled torch-0.4.1.post2\n",
            "Successfully installed dataclasses-0.8 timm-0.4.9 torch-1.9.0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1smpoSnmv_lX",
        "outputId": "8e11b69f-dd17-40d2-e2a4-0905d6734a82"
      },
      "source": [
        "!pip install h5py"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 8.9 MB/s \n",
            "\u001b[?25hCollecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/site-packages (from h5py) (1.19.2)\n",
            "Installing collected packages: cached-property, h5py\n",
            "Successfully installed cached-property-1.5.2 h5py-3.1.0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "I7d3AAmGwyu3",
        "outputId": "fd0c2904-f546-4eb1-fc87-9651fa182717"
      },
      "source": [
        "!pip install scikit-image"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 8.9 MB/s \n",
            "\u001b[?25hCollecting networkx>=2.0\n",
            "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 64.7 MB/s \n",
            "\u001b[?25hCollecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting matplotlib!=3.0.0,>=2.0.0\n",
            "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/site-packages (from scikit-image) (8.2.0)\n",
            "Collecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 53.1 MB/s \n",
            "\u001b[?25hCollecting imageio>=2.3.0\n",
            "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.6/site-packages (from scikit-image) (1.19.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/site-packages (from scikit-image) (1.5.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.16.0)\n",
            "Collecting decorator<5,>=4.3\n",
            "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: kiwisolver, decorator, cycler, tifffile, PyWavelets, networkx, matplotlib, imageio, scikit-image\n",
            "Successfully installed PyWavelets-1.1.1 cycler-0.10.0 decorator-4.4.2 imageio-2.9.0 kiwisolver-1.3.1 matplotlib-3.3.4 networkx-2.5.1 scikit-image-0.17.2 tifffile-2020.9.3\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "decorator",
                  "kiwisolver"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6bncvtLw9f2",
        "outputId": "e774db31-aa3b-43b4-f752-20aa9edc809d"
      },
      "source": [
        "!conda install ipykernel\n",
        "!python -m ipykernel install --user"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - ipykernel\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    backcall-0.2.0             |     pyhd3eb1b0_0          13 KB\n",
            "    decorator-5.0.9            |     pyhd3eb1b0_0          12 KB\n",
            "    ipykernel-5.3.4            |   py36h5ca1d4c_0         181 KB\n",
            "    ipython-7.16.1             |   py36h5ca1d4c_0         999 KB\n",
            "    ipython_genutils-0.2.0     |     pyhd3eb1b0_1          27 KB\n",
            "    jedi-0.17.0                |           py36_0         780 KB\n",
            "    jupyter_client-6.1.12      |     pyhd3eb1b0_0          88 KB\n",
            "    jupyter_core-4.7.1         |   py36h06a4308_0          68 KB\n",
            "    libsodium-1.0.18           |       h7b6447c_0         244 KB\n",
            "    parso-0.8.2                |     pyhd3eb1b0_0          69 KB\n",
            "    pexpect-4.8.0              |     pyhd3eb1b0_3          53 KB\n",
            "    pickleshare-0.7.5          |  pyhd3eb1b0_1003          13 KB\n",
            "    prompt-toolkit-3.0.17      |     pyh06a4308_0         256 KB\n",
            "    ptyprocess-0.7.0           |     pyhd3eb1b0_2          17 KB\n",
            "    pygments-2.9.0             |     pyhd3eb1b0_0         721 KB\n",
            "    pyzmq-20.0.0               |   py36h2531618_1         438 KB\n",
            "    traitlets-4.3.3            |           py36_0         140 KB\n",
            "    wcwidth-0.2.5              |             py_0          29 KB\n",
            "    zeromq-4.3.4               |       h2531618_0         331 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         4.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  backcall           pkgs/main/noarch::backcall-0.2.0-pyhd3eb1b0_0\n",
            "  decorator          pkgs/main/noarch::decorator-5.0.9-pyhd3eb1b0_0\n",
            "  ipykernel          pkgs/main/linux-64::ipykernel-5.3.4-py36h5ca1d4c_0\n",
            "  ipython            pkgs/main/linux-64::ipython-7.16.1-py36h5ca1d4c_0\n",
            "  ipython_genutils   pkgs/main/noarch::ipython_genutils-0.2.0-pyhd3eb1b0_1\n",
            "  jedi               pkgs/main/linux-64::jedi-0.17.0-py36_0\n",
            "  jupyter_client     pkgs/main/noarch::jupyter_client-6.1.12-pyhd3eb1b0_0\n",
            "  jupyter_core       pkgs/main/linux-64::jupyter_core-4.7.1-py36h06a4308_0\n",
            "  libsodium          pkgs/main/linux-64::libsodium-1.0.18-h7b6447c_0\n",
            "  parso              pkgs/main/noarch::parso-0.8.2-pyhd3eb1b0_0\n",
            "  pexpect            pkgs/main/noarch::pexpect-4.8.0-pyhd3eb1b0_3\n",
            "  pickleshare        pkgs/main/noarch::pickleshare-0.7.5-pyhd3eb1b0_1003\n",
            "  prompt-toolkit     pkgs/main/noarch::prompt-toolkit-3.0.17-pyh06a4308_0\n",
            "  ptyprocess         pkgs/main/noarch::ptyprocess-0.7.0-pyhd3eb1b0_2\n",
            "  pygments           pkgs/main/noarch::pygments-2.9.0-pyhd3eb1b0_0\n",
            "  pyzmq              pkgs/main/linux-64::pyzmq-20.0.0-py36h2531618_1\n",
            "  traitlets          pkgs/main/linux-64::traitlets-4.3.3-py36_0\n",
            "  wcwidth            pkgs/main/noarch::wcwidth-0.2.5-py_0\n",
            "  zeromq             pkgs/main/linux-64::zeromq-4.3.4-h2531618_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? ััy\n",
            "Invalid choice: ััy\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pygments-2.9.0       | 721 KB    | : 100% 1.0/1 [00:00<00:00,  5.72it/s]               \n",
            "jupyter_core-4.7.1   | 68 KB     | : 100% 1.0/1 [00:00<00:00, 13.71it/s]\n",
            "decorator-5.0.9      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 17.49it/s]\n",
            "pyzmq-20.0.0         | 438 KB    | : 100% 1.0/1 [00:00<00:00, 10.70it/s]\n",
            "ipython-7.16.1       | 999 KB    | : 100% 1.0/1 [00:00<00:00,  7.37it/s]\n",
            "pexpect-4.8.0        | 53 KB     | : 100% 1.0/1 [00:00<00:00, 14.25it/s]\n",
            "ipykernel-5.3.4      | 181 KB    | : 100% 1.0/1 [00:00<00:00, 12.73it/s]\n",
            "backcall-0.2.0       | 13 KB     | : 100% 1.0/1 [00:00<00:00, 28.71it/s]\n",
            "jupyter_client-6.1.1 | 88 KB     | : 100% 1.0/1 [00:00<00:00, 14.69it/s]\n",
            "pickleshare-0.7.5    | 13 KB     | : 100% 1.0/1 [00:00<00:00, 17.14it/s]\n",
            "wcwidth-0.2.5        | 29 KB     | : 100% 1.0/1 [00:00<00:00, 11.98it/s]\n",
            "ptyprocess-0.7.0     | 17 KB     | : 100% 1.0/1 [00:00<00:00, 17.25it/s]\n",
            "jedi-0.17.0          | 780 KB    | : 100% 1.0/1 [00:00<00:00,  4.23it/s]\n",
            "libsodium-1.0.18     | 244 KB    | : 100% 1.0/1 [00:00<00:00, 14.89it/s]\n",
            "traitlets-4.3.3      | 140 KB    | : 100% 1.0/1 [00:00<00:00, 16.54it/s]\n",
            "ipython_genutils-0.2 | 27 KB     | : 100% 1.0/1 [00:00<00:00, 17.17it/s]\n",
            "prompt-toolkit-3.0.1 | 256 KB    | : 100% 1.0/1 [00:00<00:00, 12.42it/s]\n",
            "zeromq-4.3.4         | 331 KB    | : 100% 1.0/1 [00:00<00:00, 13.70it/s]\n",
            "parso-0.8.2          | 69 KB     | : 100% 1.0/1 [00:00<00:00, 13.25it/s]\n",
            "Preparing transaction: \\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Installed kernelspec python3 in /root/.local/share/jupyter/kernels/python3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSXEM1ivzuQF"
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAgOCqPs9S97"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}